{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e842f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. è®¾ç½®å­—ä½“ä¸º \"é»‘ä½“\" (SimHei) æˆ– \"å¾®è½¯é›…é»‘\" (Microsoft YaHei)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "\n",
    "# 2. è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# FG éŸ³é¢‘æ ¹ç›®å½•ï¼ˆä½ ä¹‹å‰å·²ç»å¡«è¿‡çš„è¯ä¿æŒä¸å˜ï¼‰\n",
    "FG_WAV_ROOT = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG\")\n",
    "CG_WAV_ROOT = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\")\n",
    "\n",
    "# FG æ ‡æ³¨æ–‡ä»¶ï¼ˆGitHub ä¸Šçš„é‚£ä¸¤ä¸ªï¼‰\n",
    "FG_META_FILES = [\n",
    "    Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_train.csv\"),\n",
    "    Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_test.csv\"),\n",
    "]\n",
    "\n",
    "# CG æ ‡æ³¨æ–‡ä»¶â€”â€”ç°åœ¨å°±åªæœ‰è¿™ä¸€ä¸ª\n",
    "CG_META_FILES = [\n",
    "    Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\\label.csv\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e708e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expected_basenames(meta_files, wav_col_candidates=None):\n",
    "    \"\"\"\n",
    "    ä»è‹¥å¹²ä¸ªæ ‡æ³¨æ–‡ä»¶ä¸­ï¼ŒæŠ½å–â€œæœŸæœ›å­˜åœ¨çš„ wav æ–‡ä»¶åé›†åˆâ€\n",
    "    \"\"\"\n",
    "    if wav_col_candidates is None:\n",
    "        # æŠŠå¯èƒ½çš„åˆ—åå¤šæ”¾å‡ ä¸ªï¼Œå…¼å®¹ CG çš„ label.csv\n",
    "        wav_col_candidates = [\n",
    "            \"wav_path\", \"file\", \"filename\", \"wav\", \"path\",\n",
    "            \"audio\", \"audio_path\", \"audio_file\", \"name\"\n",
    "        ]\n",
    "\n",
    "    dfs = []\n",
    "    used_col = None\n",
    "\n",
    "    for meta_path in meta_files:\n",
    "        df = pd.read_csv(meta_path)\n",
    "        print(f\"\\n[INFO] è¯»å–æ ‡æ³¨æ–‡ä»¶: {meta_path}\")\n",
    "        print(\"[INFO] åˆ—åï¼š\", list(df.columns))\n",
    "\n",
    "        # è‡ªåŠ¨æ¢æµ‹å“ªä¸€åˆ—æ˜¯ wav è·¯å¾„\n",
    "        col = None\n",
    "        for c in wav_col_candidates:\n",
    "            if c in df.columns:\n",
    "                col = c\n",
    "                break\n",
    "        if col is None:\n",
    "            raise ValueError(\n",
    "                f\"åœ¨æ ‡æ³¨æ–‡ä»¶ {meta_path} ä¸­æ‰¾ä¸åˆ° wav è·¯å¾„åˆ—ï¼Œ\"\n",
    "                f\"è¯·æŸ¥çœ‹è¯¥ csv çš„åˆ—åï¼Œå¹¶åœ¨ wav_col_candidates ä¸­åŠ ä¸Šæ­£ç¡®åˆ—åã€‚\"\n",
    "            )\n",
    "        if used_col is None:\n",
    "            used_col = col\n",
    "        print(f\"[INFO] ä½¿ç”¨åˆ— '{col}' ä½œä¸º wav è·¯å¾„\")\n",
    "\n",
    "        sub = df[[col]].copy()\n",
    "        sub[\"basename\"] = sub[col].astype(str).apply(lambda p: Path(p).name)\n",
    "        dfs.append(sub[[\"basename\"]])\n",
    "\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # æŸ¥é‡\n",
    "    dup_counts = all_df[\"basename\"].value_counts()\n",
    "    duplicates = dup_counts[dup_counts > 1]\n",
    "\n",
    "    expected = set(all_df[\"basename\"])\n",
    "    print(f\"\\n[INFO] æ ‡æ³¨ä¸­å…±å‡ºç° {len(expected)} ä¸ªå”¯ä¸€ wav æ–‡ä»¶åï¼Œæ€»è¡Œæ•° {len(all_df)}ï¼Œ\"\n",
    "          f\"å…¶ä¸­é‡å¤æ–‡ä»¶å {len(duplicates)} ä¸ª\")\n",
    "\n",
    "    return expected, duplicates\n",
    "\n",
    "\n",
    "def scan_wav_basenames(wav_root: Path):\n",
    "    \"\"\"\n",
    "    æ‰«æç›®å½•ä¸‹æ‰€æœ‰ wavï¼Œè¿”å› basenames é›†åˆå’Œè·¯å¾„åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    wav_paths = list(wav_root.rglob(\"*.wav\"))\n",
    "    basenames = {p.name for p in wav_paths}\n",
    "    print(f\"[INFO] {wav_root} ä¸‹æ‰«æåˆ° {len(wav_paths)} ä¸ª wav æ–‡ä»¶ï¼Œ\"\n",
    "          f\"å…¶ä¸­ {len(basenames)} ä¸ªå”¯ä¸€æ–‡ä»¶å\")\n",
    "    return basenames, wav_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a073157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_train.csv ä½¿ç”¨åˆ— 'wav_path'ï¼Œå…± 45699 æ¡\n",
      "[INFO] X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_test.csv ä½¿ç”¨åˆ— 'wav_path'ï¼Œå…± 8071 æ¡\n",
      "[INFO] X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG ä¸‹æ‰«æåˆ° 53770 ä¸ª wavï¼Œ53770 ä¸ªå”¯ä¸€ stem\n",
      "[FG] æœŸæœ› stem æ•°é‡: 53770\n",
      "[FG] å®é™… stem æ•°é‡: 53770\n",
      "[FG] ç¼ºå¤± stem: 0\n",
      "[FG] å¤šä½™ stem: 0\n",
      "å‰ 10 ä¸ªç¼ºå¤± stem: []\n",
      "å‰ 10 ä¸ªå¤šä½™ stem: []\n"
     ]
    }
   ],
   "source": [
    "def load_expected_stems(meta_files, wav_col=\"wav_path\"):\n",
    "    stems = []\n",
    "    for meta_path in meta_files:\n",
    "        df = pd.read_csv(meta_path)\n",
    "        s = df[wav_col].astype(str).apply(lambda p: Path(p).stem)\n",
    "        stems.append(s)\n",
    "        print(f\"[INFO] {meta_path} ä½¿ç”¨åˆ— '{wav_col}'ï¼Œå…± {len(s)} æ¡\")\n",
    "    all_stems = pd.concat(stems, ignore_index=True)\n",
    "    unique_stems = set(all_stems.tolist())\n",
    "    return unique_stems\n",
    "\n",
    "def scan_wav_stems(wav_root: Path):\n",
    "    wav_paths = list(wav_root.rglob(\"*.wav\"))\n",
    "    stems = {p.stem for p in wav_paths}\n",
    "    print(f\"[INFO] {wav_root} ä¸‹æ‰«æåˆ° {len(wav_paths)} ä¸ª wavï¼Œ{len(stems)} ä¸ªå”¯ä¸€ stem\")\n",
    "    return stems, wav_paths\n",
    "\n",
    "# FG æ£€æŸ¥\n",
    "fg_expected_stems = load_expected_stems(FG_META_FILES, wav_col=\"wav_path\")\n",
    "fg_actual_stems, fg_paths = scan_wav_stems(FG_WAV_ROOT)\n",
    "\n",
    "fg_missing_stems = sorted(fg_expected_stems - fg_actual_stems)\n",
    "fg_extra_stems   = sorted(fg_actual_stems - fg_expected_stems)\n",
    "\n",
    "print(f\"[FG] æœŸæœ› stem æ•°é‡: {len(fg_expected_stems)}\")\n",
    "print(f\"[FG] å®é™… stem æ•°é‡: {len(fg_actual_stems)}\")\n",
    "print(f\"[FG] ç¼ºå¤± stem: {len(fg_missing_stems)}\")\n",
    "print(f\"[FG] å¤šä½™ stem: {len(fg_extra_stems)}\")\n",
    "print(\"å‰ 10 ä¸ªç¼ºå¤± stem:\", fg_missing_stems[:10])\n",
    "print(\"å‰ 10 ä¸ªå¤šä½™ stem:\", fg_extra_stems[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] è¯»å–æ ‡æ³¨æ–‡ä»¶: X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\\label.csv\n",
      "[INFO] åˆ—åï¼š ['label', 'path']\n",
      "[INFO] ä½¿ç”¨åˆ— 'path'ï¼Œå…± 49153 æ¡\n",
      "[INFO] æ ‡æ³¨ä¸­å…±å‡ºç° 49153 ä¸ªå”¯ä¸€ stem\n",
      "[INFO] X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG ä¸‹æ‰«æåˆ° 49153 ä¸ª wavï¼Œ49153 ä¸ªå”¯ä¸€ stem\n",
      "\n",
      "[CG] æ ‡æ³¨ä¸­æœŸæœ›çš„ stem æ•°é‡: 49153\n",
      "[CG] å®é™… stem æ•°é‡: 49153\n",
      "[CG] ç¼ºå¤± stem: 0\n",
      "[CG] å¤šä½™ stem: 0\n",
      "\n",
      "å‰ 10 ä¸ªç¼ºå¤± stemï¼š []\n",
      "å‰ 10 ä¸ªå¤šä½™ stemï¼š []\n"
     ]
    }
   ],
   "source": [
    "def load_expected_stems(meta_files, wav_col):\n",
    "    \"\"\"\n",
    "    ä»è‹¥å¹²ä¸ªæ ‡æ³¨æ–‡ä»¶ä¸­ï¼ŒæŠ½å–â€œæœŸæœ›å­˜åœ¨çš„ wav æ–‡ä»¶å stem é›†åˆâ€\n",
    "    wav_col: æ ‡æ³¨æ–‡ä»¶ä¸­è¡¨ç¤ºéŸ³é¢‘è·¯å¾„/æ–‡ä»¶åçš„åˆ—åï¼Œæ¯”å¦‚ 'wav_path' æˆ– 'path'\n",
    "    \"\"\"\n",
    "    stems = []\n",
    "    for meta_path in meta_files:\n",
    "        df = pd.read_csv(meta_path)\n",
    "        print(f\"[INFO] è¯»å–æ ‡æ³¨æ–‡ä»¶: {meta_path}\")\n",
    "        print(\"[INFO] åˆ—åï¼š\", list(df.columns))\n",
    "        if wav_col not in df.columns:\n",
    "            raise ValueError(f\"{meta_path} ä¸­æ‰¾ä¸åˆ°åˆ— '{wav_col}'ï¼Œè¯·æ£€æŸ¥åˆ—åã€‚\")\n",
    "        s = df[wav_col].astype(str).apply(lambda p: Path(p).stem)\n",
    "        stems.append(s)\n",
    "        print(f\"[INFO] ä½¿ç”¨åˆ— '{wav_col}'ï¼Œå…± {len(s)} æ¡\")\n",
    "\n",
    "    all_stems = pd.concat(stems, ignore_index=True)\n",
    "    unique_stems = set(all_stems.tolist())\n",
    "    print(f\"[INFO] æ ‡æ³¨ä¸­å…±å‡ºç° {len(unique_stems)} ä¸ªå”¯ä¸€ stem\")\n",
    "    return unique_stems\n",
    "\n",
    "\n",
    "def scan_wav_stems(wav_root: Path):\n",
    "    \"\"\"\n",
    "    æ‰«æç›®å½•ä¸‹æ‰€æœ‰ wavï¼Œè¿”å› stem é›†åˆå’Œå®Œæ•´è·¯å¾„åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    wav_paths = list(wav_root.rglob(\"*.wav\"))\n",
    "    stems = {p.stem for p in wav_paths}\n",
    "    print(f\"[INFO] {wav_root} ä¸‹æ‰«æåˆ° {len(wav_paths)} ä¸ª wavï¼Œ{len(stems)} ä¸ªå”¯ä¸€ stem\")\n",
    "    return stems, wav_paths\n",
    "\n",
    "# ä» label.csv ä¸­è¯»å‡ºæœŸæœ›å­˜åœ¨çš„ stem\n",
    "cg_expected_stems = load_expected_stems(\n",
    "    CG_META_FILES,\n",
    "    wav_col=\"path\"\n",
    ")\n",
    "\n",
    "# æ‰«æç›®å½•é‡Œçš„ .wavï¼Œå– stem\n",
    "cg_actual_stems, cg_paths = scan_wav_stems(CG_WAV_ROOT)\n",
    "\n",
    "# å·®é›†æ¯”è¾ƒ\n",
    "cg_missing = sorted(cg_expected_stems - cg_actual_stems)  # æ ‡æ³¨æœ‰ï¼Œç›®å½•æ²¡æœ‰\n",
    "cg_extra   = sorted(cg_actual_stems - cg_expected_stems)  # ç›®å½•æœ‰ï¼Œæ ‡æ³¨æ²¡æœ‰\n",
    "\n",
    "print(f\"\\n[CG] æ ‡æ³¨ä¸­æœŸæœ›çš„ stem æ•°é‡: {len(cg_expected_stems)}\")\n",
    "print(f\"[CG] å®é™… stem æ•°é‡: {len(cg_actual_stems)}\")\n",
    "print(f\"[CG] ç¼ºå¤± stem: {len(cg_missing)}\")\n",
    "print(f\"[CG] å¤šä½™ stem: {len(cg_extra)}\\n\")\n",
    "\n",
    "print(\"å‰ 10 ä¸ªç¼ºå¤± stemï¼š\", cg_missing[:10])\n",
    "print(\"å‰ 10 ä¸ªå¤šä½™ stemï¼š\", cg_extra[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61bd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> æ­£åœ¨åŠ è½½æ•°æ®å¹¶æå–å”¯ä¸€æ ‡è¯† (Stems)...\n",
      "\n",
      "==================== æ•°é‡ç»Ÿè®¡ ====================\n",
      "Full (Train + Test): 83920 + 15155 = 97664\n",
      "FG   (Train + Test): 45699 + 8071 = 53770\n",
      "CG   (Total)       : 49153\n",
      "\n",
      "==================== é€»è¾‘ä¸€è‡´æ€§æ ¸æŸ¥ ====================\n",
      "[FAIL] âŒ FG å’Œ CG å­˜åœ¨ 5259 ä¸ªé‡å¤æ ·æœ¬ï¼\n",
      "[PASS] âœ… Full æ•°æ®é›†å®Œç¾ç­‰äº FG + CG çš„æ€»å’Œã€‚\n",
      "        Full (97664) == FG (53770) + CG (49153)\n",
      "\n",
      "==================== æ·±å…¥åˆ†æ Full çš„æ„æˆ ====================\n",
      "Full è®­ç»ƒé›† (83920) æ„æˆ:\n",
      "   - æ¥è‡ª FG: 46835\n",
      "   - æ¥è‡ª CG: 42049\n",
      "Full æµ‹è¯•é›† (15155) æ„æˆ:\n",
      "   - æ¥è‡ª FG: 8346\n",
      "   - æ¥è‡ª CG: 8515\n",
      "\n",
      "[ç»“è®º] âŒ Full æ•°æ®é›†ä¸­åŒ…å«æœªçŸ¥çš„ç¬¬ä¸‰æ–¹æ•°æ®ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= é…ç½®è·¯å¾„ (è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹) =================\n",
    "# 1. Full (å…¨é›†) æ ‡æ³¨æ–‡ä»¶\n",
    "FULL_TRAIN_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\")\n",
    "FULL_TEST_CSV  = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_test.csv\")\n",
    "\n",
    "# 2. FG (ç»†ç²’åº¦) æ ‡æ³¨æ–‡ä»¶\n",
    "FG_TRAIN_CSV   = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_train.csv\")\n",
    "FG_TEST_CSV    = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\oceanship_fg_test.csv\")\n",
    "\n",
    "# 3. CG (ç²—ç²’åº¦) æ ‡æ³¨æ–‡ä»¶\n",
    "CG_LABEL_CSV   = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\\label.csv\")\n",
    "\n",
    "# ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================\n",
    "def get_stems(csv_path, possible_cols=['wav_path', 'path', 'filename']):\n",
    "    \"\"\"è¯»å– CSV å¹¶æå–æ–‡ä»¶åçš„ stem (ä¸å«åç¼€) ä½œä¸ºå”¯ä¸€æ ‡è¯† ID\"\"\"\n",
    "    if not csv_path.exists():\n",
    "        print(f\"[é”™è¯¯] æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}\")\n",
    "        return set()\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # è‡ªåŠ¨æ‰¾åˆ—å\n",
    "    target_col = None\n",
    "    for col in possible_cols:\n",
    "        if col in df.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "            \n",
    "    if not target_col:\n",
    "        raise ValueError(f\"åœ¨ {csv_path.name} ä¸­æ‰¾ä¸åˆ°è·¯å¾„åˆ—ï¼Œåˆ—åä¸º: {list(df.columns)}\")\n",
    "        \n",
    "    # æå– stem\n",
    "    stems = set(df[target_col].astype(str).apply(lambda x: Path(x).stem))\n",
    "    return stems\n",
    "\n",
    "# ================= å¼€å§‹æ ¸æŸ¥ =================\n",
    "print(\">>> æ­£åœ¨åŠ è½½æ•°æ®å¹¶æå–å”¯ä¸€æ ‡è¯† (Stems)...\")\n",
    "\n",
    "# 1. åŠ è½½ Full\n",
    "s_full_train = get_stems(FULL_TRAIN_CSV)\n",
    "s_full_test  = get_stems(FULL_TEST_CSV)\n",
    "s_full_all   = s_full_train | s_full_test\n",
    "\n",
    "# 2. åŠ è½½ FG\n",
    "s_fg_train   = get_stems(FG_TRAIN_CSV)\n",
    "s_fg_test    = get_stems(FG_TEST_CSV)\n",
    "s_fg_all     = s_fg_train | s_fg_test\n",
    "\n",
    "# 3. åŠ è½½ CG\n",
    "s_cg_all     = get_stems(CG_LABEL_CSV)\n",
    "\n",
    "print(f\"\\n{'='*20} æ•°é‡ç»Ÿè®¡ {'='*20}\")\n",
    "print(f\"Full (Train + Test): {len(s_full_train)} + {len(s_full_test)} = {len(s_full_all)}\")\n",
    "print(f\"FG   (Train + Test): {len(s_fg_train)} + {len(s_fg_test)} = {len(s_fg_all)}\")\n",
    "print(f\"CG   (Total)       : {len(s_cg_all)}\")\n",
    "\n",
    "# 4. æ„å»ºç†è®ºä¸Šçš„å…¨é›† (FG + CG)\n",
    "s_theoretical_all = s_fg_all | s_cg_all\n",
    "\n",
    "print(f\"\\n{'='*20} é€»è¾‘ä¸€è‡´æ€§æ ¸æŸ¥ {'='*20}\")\n",
    "\n",
    "# --- æ ¸æŸ¥ 1: FG å’Œ CG æ˜¯å¦æœ‰é‡å ? (åº”å½“æ— é‡å ) ---\n",
    "intersection = s_fg_all & s_cg_all\n",
    "if len(intersection) == 0:\n",
    "    print(\"[PASS] âœ… FG å’Œ CG äº’æ–¥ (æ— é‡å¤æ ·æœ¬)ã€‚\")\n",
    "else:\n",
    "    print(f\"[FAIL] âŒ FG å’Œ CG å­˜åœ¨ {len(intersection)} ä¸ªé‡å¤æ ·æœ¬ï¼\")\n",
    "\n",
    "# --- æ ¸æŸ¥ 2: Full æ˜¯å¦ç­‰äº FG + CG? ---\n",
    "missing_in_full = s_theoretical_all - s_full_all  # FG/CG æœ‰ï¼Œä½† Full æ²¡æ”¶å½•\n",
    "extra_in_full   = s_full_all - s_theoretical_all  # Full æœ‰ï¼Œä½† FG/CG æ²¡æ‰¾åˆ°\n",
    "\n",
    "if len(missing_in_full) == 0 and len(extra_in_full) == 0:\n",
    "    print(\"[PASS] âœ… Full æ•°æ®é›†å®Œç¾ç­‰äº FG + CG çš„æ€»å’Œã€‚\")\n",
    "    print(f\"        Full ({len(s_full_all)}) == FG ({len(s_fg_all)}) + CG ({len(s_cg_all)})\")\n",
    "else:\n",
    "    print(\"[FAIL] âŒ é›†åˆä¸åŒ¹é…ï¼\")\n",
    "    if missing_in_full:\n",
    "        print(f\"   - è­¦å‘Š: {len(missing_in_full)} ä¸ªæ ·æœ¬åœ¨ FG/CG ä¸­å­˜åœ¨ï¼Œä½†åœ¨ Full ä¸­ä¸¢å¤±ã€‚\")\n",
    "    if extra_in_full:\n",
    "        print(f\"   - è­¦å‘Š: {len(extra_in_full)} ä¸ªæ ·æœ¬åœ¨ Full ä¸­å­˜åœ¨ï¼Œä½†æ¥æºä¸æ˜ (éFGéCG)ã€‚\")\n",
    "\n",
    "# --- æ ¸æŸ¥ 3: è®­ç»ƒé›†/æµ‹è¯•é›†çš„æˆåˆ†åˆ†æ ---\n",
    "print(f\"\\n{'='*20} æ·±å…¥åˆ†æ Full çš„æ„æˆ {'='*20}\")\n",
    "# çœ‹çœ‹ Full çš„è®­ç»ƒé›†ä¸­ï¼ŒåŒ…å«äº†å¤šå°‘ FG å’Œ CG\n",
    "full_train_from_fg = s_full_train & s_fg_all\n",
    "full_train_from_cg = s_full_train & s_cg_all\n",
    "\n",
    "# çœ‹çœ‹ Full çš„æµ‹è¯•é›†ä¸­ï¼ŒåŒ…å«äº†å¤šå°‘ FG å’Œ CG\n",
    "full_test_from_fg = s_full_test & s_fg_all\n",
    "full_test_from_cg = s_full_test & s_cg_all\n",
    "\n",
    "print(f\"Full è®­ç»ƒé›† ({len(s_full_train)}) æ„æˆ:\")\n",
    "print(f\"   - æ¥è‡ª FG: {len(full_train_from_fg)}\")\n",
    "print(f\"   - æ¥è‡ª CG: {len(full_train_from_cg)}\")\n",
    "\n",
    "print(f\"Full æµ‹è¯•é›† ({len(s_full_test)}) æ„æˆ:\")\n",
    "print(f\"   - æ¥è‡ª FG: {len(full_test_from_fg)}\")\n",
    "print(f\"   - æ¥è‡ª CG: {len(full_test_from_cg)}\")\n",
    "\n",
    "# æ ¡éªŒæ€»å’Œ\n",
    "if (len(full_train_from_fg) + len(full_train_from_cg) == len(s_full_train)) and \\\n",
    "   (len(full_test_from_fg) + len(full_test_from_cg) == len(s_full_test)):\n",
    "     print(\"\\n[ç»“è®º] âœ… Full æ•°æ®é›†çš„æ¯ä¸€æ¡æ•°æ®æ¥æºéƒ½æ¸…æ™°æ˜ç¡®ã€‚\")\n",
    "else:\n",
    "     print(\"\\n[ç»“è®º] âŒ Full æ•°æ®é›†ä¸­åŒ…å«æœªçŸ¥çš„ç¬¬ä¸‰æ–¹æ•°æ®ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e1ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> æ­£åœ¨è¯»å– CSV å’Œæ‰«æç¡¬ç›˜ï¼Œè¯·ç¨å€™...\n",
      "[1] CSV æœŸæœ›æ–‡ä»¶æ•° : 83920\n",
      "[2] Train å®é™…æ–‡ä»¶æ•°: 68399\n",
      "[3] ç¼ºå¤±æ–‡ä»¶æ€»æ•°   : 15521\n",
      "\n",
      ">>> æ­£åœ¨å» FG å’Œ CG æºæ–‡ä»¶å¤¹é‡Œå¯»æ‰¾ä¸‹è½...\n",
      "==============================\n",
      "æœæ•‘æŠ¥å‘Š (ç¼ºå¤±æ€»æ•°: 15521)\n",
      "==============================\n",
      "âœ… åœ¨ FG ä¸­æ‰¾åˆ° : 6385 ä¸ª\n",
      "âœ… åœ¨ CG ä¸­æ‰¾åˆ° : 9522 ä¸ª\n",
      "   (å…¶ä¸­ 386 ä¸ªåŒæ—¶å­˜åœ¨äº FG å’Œ CG)\n",
      "------------------------------\n",
      "ğŸ‰ å¯æ¢å¤æ€»æ•°   : 15521 ä¸ª (å æ¯” 100.0%)\n",
      "âŒ å½»åº•ä¸¢å¤±     : 0 ä¸ª\n",
      "\n",
      "[æç¤º] å¯ä»¥åœ¨ä¸‹ä¸€æ­¥é€šè¿‡è„šæœ¬å°†æ‰¾åˆ°çš„æ–‡ä»¶å¤åˆ¶è¿‡å»ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= 1. é…ç½®è·¯å¾„ (è¯·ç¡®è®¤ä½ çš„å®é™…è·¯å¾„) =================\n",
    "# ç›®æ ‡ï¼šéœ€è¦æ£€æŸ¥çš„ Train æ–‡ä»¶å¤¹ (OceanShip_2)\n",
    "TRAIN_DIR_BAD = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_train\")\n",
    "# ç´¢å¼•ï¼šå®˜æ–¹çš„ Full Train CSV\n",
    "TRAIN_CSV     = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\")\n",
    "\n",
    "# æºå¤´ï¼šåŸæ¥çš„ FG å’Œ CG æ–‡ä»¶å¤¹ (OceanShip_1)\n",
    "SOURCE_FG_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG\")\n",
    "SOURCE_CG_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\")\n",
    "\n",
    "# ================= 2. æ ¸å¿ƒå·¥å…·å‡½æ•° =================\n",
    "def get_stems_from_dir(dir_path):\n",
    "    \"\"\"æ‰«æç›®å½•ä¸‹çš„ wav æ–‡ä»¶ï¼Œè¿”å› {stem: full_path} çš„å­—å…¸\"\"\"\n",
    "    if not dir_path.exists():\n",
    "        print(f\"[é”™è¯¯] æ‰¾ä¸åˆ°ç›®å½•: {dir_path}\")\n",
    "        return {}\n",
    "    # ä½¿ç”¨å­—å…¸åŒæ—¶ä¿å­˜ stem å’Œ å®Œæ•´è·¯å¾„ï¼Œæ–¹ä¾¿åç»­å®šä½\n",
    "    return {p.stem: p for p in dir_path.rglob(\"*.wav\")}\n",
    "\n",
    "def get_stems_from_csv(csv_path):\n",
    "    \"\"\"ä» CSV è¯»å–æœŸæœ›çš„ stem é›†åˆ\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # å‡è®¾åˆ—åæ˜¯ 'wav_path'ï¼Œå¦‚æœæŠ¥é”™è¯·æ”¹ä¸º 'path' æˆ–å…¶ä»–\n",
    "    col_name = 'wav_path' if 'wav_path' in df.columns else 'path'\n",
    "    return set(df[col_name].apply(lambda x: Path(x).stem))\n",
    "\n",
    "# ================= 3. å¼€å§‹æ‰§è¡Œæœæ•‘ä»»åŠ¡ =================\n",
    "print(\">>> æ­£åœ¨è¯»å– CSV å’Œæ‰«æç¡¬ç›˜ï¼Œè¯·ç¨å€™...\")\n",
    "\n",
    "# A. è·å–â€œåº”è¯¥æœ‰â€çš„åå•\n",
    "expected_stems = get_stems_from_csv(TRAIN_CSV)\n",
    "print(f\"[1] CSV æœŸæœ›æ–‡ä»¶æ•° : {len(expected_stems)}\")\n",
    "\n",
    "# B. è·å–â€œå®é™…æœ‰â€çš„åå• (Oceanship_train)\n",
    "current_train_files = get_stems_from_dir(TRAIN_DIR_BAD)\n",
    "current_train_stems = set(current_train_files.keys())\n",
    "print(f\"[2] Train å®é™…æ–‡ä»¶æ•°: {len(current_train_stems)}\")\n",
    "\n",
    "# C. è®¡ç®—ç¼ºå¤±åå•\n",
    "missing_stems = expected_stems - current_train_stems\n",
    "print(f\"[3] ç¼ºå¤±æ–‡ä»¶æ€»æ•°   : {len(missing_stems)}\")\n",
    "\n",
    "if len(missing_stems) == 0:\n",
    "    print(\"\\nâœ… å®Œç¾ï¼æ²¡æœ‰ç¼ºå¤±æ–‡ä»¶ã€‚\")\n",
    "else:\n",
    "    print(\"\\n>>> æ­£åœ¨å» FG å’Œ CG æºæ–‡ä»¶å¤¹é‡Œå¯»æ‰¾ä¸‹è½...\")\n",
    "    \n",
    "    # D. æ‰«ææºæ–‡ä»¶å¤¹\n",
    "    fg_files = get_stems_from_dir(SOURCE_FG_DIR)\n",
    "    cg_files = get_stems_from_dir(SOURCE_CG_DIR)\n",
    "    \n",
    "    fg_stems = set(fg_files.keys())\n",
    "    cg_stems = set(cg_files.keys())\n",
    "    \n",
    "    # E. äº¤å‰æ ¸å¯¹\n",
    "    found_in_fg = missing_stems & fg_stems\n",
    "    found_in_cg = missing_stems & cg_stems\n",
    "    found_in_both = found_in_fg & found_in_cg\n",
    "    \n",
    "    # è®¡ç®—èƒ½æ‰¾å›çš„æ€»æ•° (å¹¶é›†)\n",
    "    recoverable = found_in_fg | found_in_cg\n",
    "    truly_lost  = missing_stems - recoverable\n",
    "    \n",
    "    print(f\"{'='*30}\")\n",
    "    print(f\"æœæ•‘æŠ¥å‘Š (ç¼ºå¤±æ€»æ•°: {len(missing_stems)})\")\n",
    "    print(f\"{'='*30}\")\n",
    "    print(f\"âœ… åœ¨ FG ä¸­æ‰¾åˆ° : {len(found_in_fg)} ä¸ª\")\n",
    "    print(f\"âœ… åœ¨ CG ä¸­æ‰¾åˆ° : {len(found_in_cg)} ä¸ª\")\n",
    "    print(f\"   (å…¶ä¸­ {len(found_in_both)} ä¸ªåŒæ—¶å­˜åœ¨äº FG å’Œ CG)\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"ğŸ‰ å¯æ¢å¤æ€»æ•°   : {len(recoverable)} ä¸ª (å æ¯” {len(recoverable)/len(missing_stems):.1%})\")\n",
    "    print(f\"âŒ å½»åº•ä¸¢å¤±     : {len(truly_lost)} ä¸ª\")\n",
    "    \n",
    "    # F. æ‰“å°ä¸€äº›æ ·ä¾‹\n",
    "    if len(truly_lost) > 0:\n",
    "        print(\"\\n[è­¦å‘Š] ä»¥ä¸‹æ–‡ä»¶åœ¨ FG å’Œ CG é‡Œéƒ½æ‰¾ä¸åˆ° (å¯èƒ½æ˜¯åŸå§‹æ•°æ®æœ¬èº«å°±ç¼ºå¤±):\")\n",
    "        print(list(truly_lost)[:5])\n",
    "    \n",
    "    if len(recoverable) > 0:\n",
    "        print(\"\\n[æç¤º] å¯ä»¥åœ¨ä¸‹ä¸€æ­¥é€šè¿‡è„šæœ¬å°†æ‰¾åˆ°çš„æ–‡ä»¶å¤åˆ¶è¿‡å»ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [Testé›†] æ­£åœ¨è¯»å– CSV å’Œæ‰«æç¡¬ç›˜ï¼Œè¯·ç¨å€™...\n",
      "[1] CSV æœŸæœ›æ–‡ä»¶æ•° : 15155\n",
      "[2] Test å®é™…æ–‡ä»¶æ•° : 15155\n",
      "[3] ç¼ºå¤±æ–‡ä»¶æ€»æ•°   : 0\n",
      "\n",
      "âœ… å®Œç¾ï¼Test é›†æ²¡æœ‰ç¼ºå¤±æ–‡ä»¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= 1. é…ç½®è·¯å¾„ =================\n",
    "# ç›®æ ‡ï¼šéœ€è¦æ£€æŸ¥çš„ Test æ–‡ä»¶å¤¹ (æ¨æµ‹åœ¨ OceanShip_2 ä¸‹)\n",
    "TEST_DIR_BAD = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_test\")\n",
    "\n",
    "# ç´¢å¼•ï¼šå®˜æ–¹çš„ Full Test CSV\n",
    "TEST_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_test.csv\")\n",
    "\n",
    "# æºå¤´ï¼šåŸæ¥çš„ FG å’Œ CG æ–‡ä»¶å¤¹ (ä¿æŒä¸å˜)\n",
    "SOURCE_FG_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG\")\n",
    "SOURCE_CG_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\")\n",
    "\n",
    "# ================= 2. æ ¸å¿ƒå·¥å…·å‡½æ•° (ä¸ä¹‹å‰ä¸€è‡´) =================\n",
    "def get_stems_from_dir(dir_path):\n",
    "    \"\"\"æ‰«æç›®å½•ä¸‹çš„ wav æ–‡ä»¶ï¼Œè¿”å› {stem: full_path} çš„å­—å…¸\"\"\"\n",
    "    if not dir_path.exists():\n",
    "        print(f\"[é”™è¯¯] æ‰¾ä¸åˆ°ç›®å½•: {dir_path}\")\n",
    "        return {}\n",
    "    return {p.stem: p for p in dir_path.rglob(\"*.wav\")}\n",
    "\n",
    "def get_stems_from_csv(csv_path):\n",
    "    \"\"\"ä» CSV è¯»å–æœŸæœ›çš„ stem é›†åˆ\"\"\"\n",
    "    if not csv_path.exists():\n",
    "         print(f\"[é”™è¯¯] æ‰¾ä¸åˆ° CSV: {csv_path}\")\n",
    "         return set()\n",
    "    df = pd.read_csv(csv_path)\n",
    "    col_name = 'wav_path' if 'wav_path' in df.columns else 'path'\n",
    "    return set(df[col_name].apply(lambda x: Path(x).stem))\n",
    "\n",
    "# ================= 3. å¼€å§‹æ‰§è¡Œæœæ•‘ä»»åŠ¡ (Test é›†) =================\n",
    "print(\">>> [Testé›†] æ­£åœ¨è¯»å– CSV å’Œæ‰«æç¡¬ç›˜ï¼Œè¯·ç¨å€™...\")\n",
    "\n",
    "# A. è·å–â€œåº”è¯¥æœ‰â€çš„åå•\n",
    "expected_stems = get_stems_from_csv(TEST_CSV)\n",
    "print(f\"[1] CSV æœŸæœ›æ–‡ä»¶æ•° : {len(expected_stems)}\")\n",
    "\n",
    "# B. è·å–â€œå®é™…æœ‰â€çš„åå•\n",
    "current_test_files = get_stems_from_dir(TEST_DIR_BAD)\n",
    "current_test_stems = set(current_test_files.keys())\n",
    "print(f\"[2] Test å®é™…æ–‡ä»¶æ•° : {len(current_test_stems)}\")\n",
    "\n",
    "# C. è®¡ç®—ç¼ºå¤±åå•\n",
    "missing_stems = expected_stems - current_test_stems\n",
    "print(f\"[3] ç¼ºå¤±æ–‡ä»¶æ€»æ•°   : {len(missing_stems)}\")\n",
    "\n",
    "if len(missing_stems) == 0:\n",
    "    print(\"\\nâœ… å®Œç¾ï¼Test é›†æ²¡æœ‰ç¼ºå¤±æ–‡ä»¶ã€‚\")\n",
    "else:\n",
    "    print(\"\\n>>> æ­£åœ¨å» FG å’Œ CG æºæ–‡ä»¶å¤¹é‡Œå¯»æ‰¾ä¸‹è½...\")\n",
    "    \n",
    "    # D. æ‰«ææºæ–‡ä»¶å¤¹\n",
    "    fg_files = get_stems_from_dir(SOURCE_FG_DIR)\n",
    "    cg_files = get_stems_from_dir(SOURCE_CG_DIR)\n",
    "    \n",
    "    fg_stems = set(fg_files.keys())\n",
    "    cg_stems = set(cg_files.keys())\n",
    "    \n",
    "    # E. äº¤å‰æ ¸å¯¹\n",
    "    found_in_fg = missing_stems & fg_stems\n",
    "    found_in_cg = missing_stems & cg_stems\n",
    "    \n",
    "    # è®¡ç®—èƒ½æ‰¾å›çš„æ€»æ•°\n",
    "    recoverable = found_in_fg | found_in_cg\n",
    "    truly_lost  = missing_stems - recoverable\n",
    "    \n",
    "    print(f\"{'='*30}\")\n",
    "    print(f\"æœæ•‘æŠ¥å‘Š (Test ç¼ºå¤±æ€»æ•°: {len(missing_stems)})\")\n",
    "    print(f\"{'='*30}\")\n",
    "    print(f\"âœ… åœ¨ FG ä¸­æ‰¾åˆ° : {len(found_in_fg)} ä¸ª\")\n",
    "    print(f\"âœ… åœ¨ CG ä¸­æ‰¾åˆ° : {len(found_in_cg)} ä¸ª\")\n",
    "    print(f\"{'-'*30}\")\n",
    "    print(f\"ğŸ‰ å¯æ¢å¤æ€»æ•°   : {len(recoverable)} ä¸ª\")\n",
    "    print(f\"âŒ å½»åº•ä¸¢å¤±     : {len(truly_lost)} ä¸ª\")\n",
    "    \n",
    "    if len(truly_lost) > 0:\n",
    "        print(\"\\n[è­¦å‘Š] ä»¥ä¸‹æ–‡ä»¶åœ¨ FG å’Œ CG é‡Œéƒ½æ‰¾ä¸åˆ° (éœ€è¦ä» CSV ä¸­å‰”é™¤):\")\n",
    "        print(list(truly_lost)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd6b22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> æ­£åœ¨åˆå§‹åŒ–ä¿®å¤ç¨‹åº...\n",
      "[ç›®æ ‡] è®­ç»ƒé›†åº”åŒ…å«: 83920 ä¸ªå”¯ä¸€æ–‡ä»¶\n",
      "[ç°çŠ¶] å½“å‰ç¼ºå¤±æ•°é‡: 15521\n",
      ">>> å¼€å§‹ä»æºæ–‡ä»¶å¤¹æœå¯»å¹¶å¤åˆ¶ 15521 ä¸ªæ–‡ä»¶...\n",
      "    æ­£åœ¨ç´¢å¼•æºç›®å½•: X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG ...\n",
      "    æ­£åœ¨ç´¢å¼•æºç›®å½•: X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ä¿®å¤è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15521/15521 [01:40<00:00, 153.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ä¿®å¤å®ŒæˆæŠ¥å‘Š\n",
      "==============================\n",
      "âœ… æˆåŠŸä¿®å¤: 15521 ä¸ªæ–‡ä»¶\n",
      "âŒ æ— æ³•æ‰¾å›: 0 ä¸ªæ–‡ä»¶ (å¯èƒ½æºæ–‡ä»¶ä¸­ä¹Ÿä¸å­˜åœ¨)\n",
      "å½“å‰ Train æ–‡ä»¶å¤¹æ€»æ•°: 83920\n"
     ]
    }
   ],
   "source": [
    "# ================= é…ç½®è·¯å¾„ =================\n",
    "# 1. ç›®çš„åœ°ï¼šç¼ºå¤±æ–‡ä»¶çš„ Train æ–‡ä»¶å¤¹\n",
    "DEST_TRAIN_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_train\")\n",
    "\n",
    "# 2. ç´¢å¼•ï¼šå®˜æ–¹ Full Train CSV (ç”¨æ¥çŸ¥é“ç¼ºäº†è°)\n",
    "TRAIN_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\")\n",
    "\n",
    "# 3. è¡¥ç»™ç«™ï¼šæº FG å’Œ CG æ–‡ä»¶å¤¹\n",
    "SOURCE_DIRS = [\n",
    "    Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-FG\"),\n",
    "    Path(r\"X:\\æ•°æ®é›†\\OceanShip_1\\OceanShip-CG\")\n",
    "]\n",
    "\n",
    "# ================= æ ¸å¿ƒé€»è¾‘ =================\n",
    "print(\">>> æ­£åœ¨åˆå§‹åŒ–ä¿®å¤ç¨‹åº...\")\n",
    "\n",
    "# 1. è¯»å–éœ€è¦çš„æ‰€æœ‰ stem\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "# å…¼å®¹åˆ—å\n",
    "col = 'wav_path' if 'wav_path' in df.columns else 'path'\n",
    "expected_stems = set(df[col].apply(lambda x: Path(x).stem))\n",
    "print(f\"[ç›®æ ‡] è®­ç»ƒé›†åº”åŒ…å«: {len(expected_stems)} ä¸ªå”¯ä¸€æ–‡ä»¶\")\n",
    "\n",
    "# 2. æ‰«æç°æœ‰çš„ stem\n",
    "current_files = {p.stem for p in DEST_TRAIN_DIR.glob(\"*.wav\")}\n",
    "missing_stems = expected_stems - current_files\n",
    "print(f\"[ç°çŠ¶] å½“å‰ç¼ºå¤±æ•°é‡: {len(missing_stems)}\")\n",
    "\n",
    "if len(missing_stems) == 0:\n",
    "    print(\"âœ… è®­ç»ƒé›†å·²ç»å®Œæ•´ï¼Œæ— éœ€ä¿®å¤ï¼\")\n",
    "else:\n",
    "    print(f\">>> å¼€å§‹ä»æºæ–‡ä»¶å¤¹æœå¯»å¹¶å¤åˆ¶ {len(missing_stems)} ä¸ªæ–‡ä»¶...\")\n",
    "    \n",
    "    # 3. å»ºç«‹æºæ–‡ä»¶ç´¢å¼• (stem -> full_path)\n",
    "    #    ä¸ºäº†åŠ å¿«é€Ÿåº¦ï¼Œå…ˆæ‰«ä¸€éæºç›®å½•\n",
    "    source_map = {}\n",
    "    for src_dir in SOURCE_DIRS:\n",
    "        if src_dir.exists():\n",
    "            print(f\"    æ­£åœ¨ç´¢å¼•æºç›®å½•: {src_dir} ...\")\n",
    "            for p in src_dir.rglob(\"*.wav\"):\n",
    "                source_map[p.stem] = p\n",
    "        else:\n",
    "            print(f\"    [è­¦å‘Š] æºç›®å½•ä¸å­˜åœ¨: {src_dir}\")\n",
    "\n",
    "    # 4. æ‰§è¡Œå¤åˆ¶\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦\n",
    "    for stem in tqdm(missing_stems, desc=\"ä¿®å¤è¿›åº¦\"):\n",
    "        if stem in source_map:\n",
    "            src_file = source_map[stem]\n",
    "            dst_file = DEST_TRAIN_DIR / src_file.name\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                success_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"    [å¤åˆ¶å¤±è´¥] {src_file.name}: {e}\")\n",
    "                fail_count += 1\n",
    "        else:\n",
    "            # æºé‡Œä¹Ÿæ‰¾ä¸åˆ°ï¼ˆé‚£æ˜¯çœŸçš„ä¸¢äº†ï¼‰\n",
    "            fail_count += 1\n",
    "            \n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"ä¿®å¤å®ŒæˆæŠ¥å‘Š\")\n",
    "    print(f\"{'='*30}\")\n",
    "    print(f\"âœ… æˆåŠŸä¿®å¤: {success_count} ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"âŒ æ— æ³•æ‰¾å›: {fail_count} ä¸ªæ–‡ä»¶ (å¯èƒ½æºæ–‡ä»¶ä¸­ä¹Ÿä¸å­˜åœ¨)\")\n",
    "    print(f\"å½“å‰ Train æ–‡ä»¶å¤¹æ€»æ•°: {len(list(DEST_TRAIN_DIR.glob('*.wav')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2367ab",
   "metadata": {},
   "source": [
    "# Trainæ–‡ä»¶å¤¹æ ‡æ³¨å»é‡å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e99f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ‡æ³¨åˆ—åï¼š ['wav_path', 'label', 'text_path']\n",
      "åŸæ ‡æ³¨è¡Œæ•°ï¼š 87473\n",
      "æ ‡æ³¨ä¸­çš„å”¯ä¸€ stem æ•°é‡ï¼š 83920\n",
      "\n",
      "X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_train ä¸‹å…±æ‰¾åˆ° 83920 ä¸ª wav æ–‡ä»¶ï¼Œ83920 ä¸ªå”¯ä¸€ stemã€‚\n",
      "\n",
      "[Train æ£€æŸ¥ç»“æœ]\n",
      "æ ‡æ³¨æœŸæœ›çš„ stem æ•°é‡: 83920\n",
      "å®é™… wav stem æ•°é‡: 83920\n",
      "ç¼ºå¤±çš„ wav æ•°é‡: 0\n",
      "å¤šä½™çš„ wav æ•°é‡: 0\n",
      "\n",
      "å‰ 10 ä¸ªç¼ºå¤±çš„ stemï¼š []\n",
      "å‰ 10 ä¸ªå¤šä½™çš„ stemï¼š []\n"
     ]
    }
   ],
   "source": [
    "# 1. é…ç½®è·¯å¾„ï¼šæ ¹æ®ä½ æœ¬åœ°æƒ…å†µä¿®æ”¹\n",
    "META_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\")\n",
    "WAV_ROOT = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_train\")\n",
    "\n",
    "WAV_COL_NAME = \"wav_path\"  # æ ‡æ³¨ä¸­è¡¨ç¤ºéŸ³é¢‘è·¯å¾„çš„åˆ—å\n",
    "\n",
    "# 2. è¯»å–æ ‡æ³¨ï¼Œç»Ÿè®¡è¡Œæ•°å’Œå”¯ä¸€ stem æ•°\n",
    "df = pd.read_csv(META_CSV)\n",
    "print(\"æ ‡æ³¨åˆ—åï¼š\", list(df.columns))\n",
    "print(\"åŸæ ‡æ³¨è¡Œæ•°ï¼š\", len(df))\n",
    "\n",
    "# å– stemï¼ˆå»æ‰ç›®å½•å’Œåç¼€ï¼‰\n",
    "df[\"stem\"] = df[WAV_COL_NAME].astype(str).apply(lambda p: Path(p).stem)\n",
    "\n",
    "expected_stems = df[\"stem\"]\n",
    "expected_stem_set = set(expected_stems.tolist())\n",
    "print(\"æ ‡æ³¨ä¸­çš„å”¯ä¸€ stem æ•°é‡ï¼š\", len(expected_stem_set))\n",
    "\n",
    "# 3. æ‰«æ train ç›®å½•ä¸‹æ‰€æœ‰ wavï¼Œç»Ÿè®¡å®é™… stem é›†åˆ\n",
    "wav_paths = list(WAV_ROOT.rglob(\"*.wav\"))\n",
    "actual_stem_set = {p.stem for p in wav_paths}\n",
    "\n",
    "print(f\"\\n{WAV_ROOT} ä¸‹å…±æ‰¾åˆ° {len(wav_paths)} ä¸ª wav æ–‡ä»¶ï¼Œ\"\n",
    "      f\"{len(actual_stem_set)} ä¸ªå”¯ä¸€ stemã€‚\")\n",
    "\n",
    "# 4. è®¡ç®—å·®é›†ï¼šç¼ºå¤± / å¤šä½™\n",
    "missing_stems = sorted(expected_stem_set - actual_stem_set)  # æ ‡æ³¨æœ‰ï¼Œç›®å½•æ²¡æœ‰\n",
    "extra_stems   = sorted(actual_stem_set - expected_stem_set)  # ç›®å½•æœ‰ï¼Œæ ‡æ³¨æ²¡æœ‰\n",
    "\n",
    "print(\"\\n[Train æ£€æŸ¥ç»“æœ]\")\n",
    "print(f\"æ ‡æ³¨æœŸæœ›çš„ stem æ•°é‡: {len(expected_stem_set)}\")\n",
    "print(f\"å®é™… wav stem æ•°é‡: {len(actual_stem_set)}\")\n",
    "print(f\"ç¼ºå¤±çš„ wav æ•°é‡: {len(missing_stems)}\")\n",
    "print(f\"å¤šä½™çš„ wav æ•°é‡: {len(extra_stems)}\")\n",
    "\n",
    "print(\"\\nå‰ 10 ä¸ªç¼ºå¤±çš„ stemï¼š\", missing_stems[:10])\n",
    "print(\"å‰ 10 ä¸ªå¤šä½™çš„ stemï¼š\", extra_stems[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dec5377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸºäºæ–‡ä»¶å(Stem)æ‰¾åˆ°çš„é‡å¤è®°å½•æ•°: 7106\n",
      "\n",
      "=== é‡å¤æ ·æœ¬å¯¹æ¯” (è¯·æ³¨æ„è§‚å¯Ÿ wav_path çš„åŒºåˆ«) ===\n",
      "[0] Path: ./3090latest_wav/20210107T131611.740Z_1644_id_24_typecargo_37_0.pt\n",
      "    Stem: 20210107T131611.740Z_1644_id_24_typecargo_37_0\n",
      "------------------------------\n",
      "[1] Path: ./v100_preprocessed_89_09_31/20210107T131611.740Z_1644_id_24_typecargo_37_0.pt\n",
      "    Stem: 20210107T131611.740Z_1644_id_24_typecargo_37_0\n",
      "------------------------------\n",
      "[2] Path: ./v100_preprocessed_89_09_31/20210107T131611.740Z_1644_id_24_typecargo_37_1.pt\n",
      "    Stem: 20210107T131611.740Z_1644_id_24_typecargo_37_1\n",
      "------------------------------\n",
      "[3] Path: ./3090latest_wav/20210107T131611.740Z_1644_id_24_typecargo_37_1.pt\n",
      "    Stem: 20210107T131611.740Z_1644_id_24_typecargo_37_1\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CSV_PATH = r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\"\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "col = 'wav_path' if 'wav_path' in df.columns else 'path'\n",
    "\n",
    "# 1. åˆ›å»ºä¸´æ—¶çš„ Stem åˆ—\n",
    "df['temp_stem'] = df[col].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# 2. åŸºäº Stem æŸ¥æ‰¾é‡å¤\n",
    "dups = df[df.duplicated(subset=['temp_stem'], keep=False)].sort_values(by='temp_stem')\n",
    "\n",
    "print(f\"åŸºäºæ–‡ä»¶å(Stem)æ‰¾åˆ°çš„é‡å¤è®°å½•æ•°: {len(dups)}\")\n",
    "print(\"\\n=== é‡å¤æ ·æœ¬å¯¹æ¯” (è¯·æ³¨æ„è§‚å¯Ÿ wav_path çš„åŒºåˆ«) ===\")\n",
    "# æ‰“å°å‰ 4 è¡Œï¼Œå³ 2 å¯¹é‡å¤æ ·æœ¬\n",
    "# ä½ ä¼šå‘ç° wav_path å¯èƒ½ä¸€ä¸ªæ˜¯ .../FG/...ï¼Œä¸€ä¸ªæ˜¯ .../CG/...\n",
    "for i in range(0, min(4, len(dups))):\n",
    "    row = dups.iloc[i]\n",
    "    print(f\"[{i}] Path: {row[col]}\")\n",
    "    print(f\"    Stem: {row['temp_stem']}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# æ¸…ç†ä¸´æ—¶åˆ—ï¼ˆå¦‚æœéœ€è¦ç»§ç»­ä½¿ç”¨ dfï¼‰\n",
    "df.drop(columns=['temp_stem'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edf1e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> å¼€å§‹ç”Ÿæˆå»é‡ç‰ˆè®­ç»ƒç´¢å¼• (ä¿ç•™åŸè·¯å¾„)...\n",
      "åŸå§‹è¡Œæ•°: 87473\n",
      "å»é‡åè¡Œæ•°: 83920 (ç†è®ºåº”ä¸º 83920)\n",
      ">>>ä»¥æ­¤é…ç½®è·³è¿‡è·¯å¾„ä¿®æ”¹ï¼Œä¿ç•™ CSV ä¸­çš„åŸå§‹è·¯å¾„ string...\n",
      ">>> æ­£åœ¨éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (åŸºäº stem åŒ¹é…)...\n",
      "âœ… å®Œç¾ï¼å»é‡åçš„ 83920 æ¡è®°å½•åœ¨çœŸå®ç›®å½•ä¸‹éƒ½èƒ½æ‰¾åˆ°å¯¹åº”çš„ .wav æ–‡ä»¶ã€‚\n",
      "\n",
      "å·²ä¿å­˜æœ€ç»ˆæ–‡ä»¶åˆ°: X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_train_dedup.csv\n",
      "æ³¨æ„ï¼šç”Ÿæˆçš„ CSV ä¸­ 'wav_path' åˆ—ä¾ç„¶ä¿æŒåŸå§‹æ ¼å¼ (å¦‚ .pt åç¼€æˆ–æ—§ç›¸å¯¹è·¯å¾„)ã€‚\n",
      "è¯·ç¡®ä¿ä½ çš„ Dataset/DataLoader ä»£ç èƒ½æ­£ç¡®å¤„ç†è¿™äº›è·¯å¾„ï¼ˆä¾‹å¦‚æ‰‹åŠ¨æ‹¼æ¥ root ç›®å½•æˆ–æ›¿æ¢åç¼€ï¼‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= é…ç½®è·¯å¾„ =================\n",
    "# 1. åŸå§‹æ··ä¹±çš„ CSV\n",
    "RAW_CSV_PATH = r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_train.csv\"\n",
    "\n",
    "# 2. ä½ ç°åœ¨çš„çœŸå®éŸ³é¢‘ç›®å½• (ä»…ç”¨æ¥éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸ä¼šä¿®æ”¹ CSV è·¯å¾„)\n",
    "REAL_WAV_DIR = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_train\")\n",
    "\n",
    "# 3. è¾“å‡ºçš„æ–° CSV è·¯å¾„\n",
    "OUTPUT_CSV_PATH = r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_train_dedup.csv\"\n",
    "\n",
    "# ================= æ‰§è¡Œä¿®å¤ =================\n",
    "print(\">>> å¼€å§‹ç”Ÿæˆå»é‡ç‰ˆè®­ç»ƒç´¢å¼• (ä¿ç•™åŸè·¯å¾„)...\")\n",
    "\n",
    "# 1. è¯»å–åŸå§‹ CSV\n",
    "df = pd.read_csv(RAW_CSV_PATH)\n",
    "col = 'wav_path' if 'wav_path' in df.columns else 'path'\n",
    "print(f\"åŸå§‹è¡Œæ•°: {len(df)}\")\n",
    "\n",
    "# 2. æå– Stem å¹¶å»é‡\n",
    "# é€»è¾‘ï¼šæ–°å¢ä¸€åˆ— stemï¼Œåˆ©ç”¨å®ƒå»é‡ï¼Œä¿ç•™ç¬¬ä¸€æ¡è®°å½•\n",
    "df['stem'] = df[col].apply(lambda x: Path(x).stem)\n",
    "df_clean = df.drop_duplicates(subset=['stem'], keep='first').copy()\n",
    "print(f\"å»é‡åè¡Œæ•°: {len(df_clean)} (ç†è®ºåº”ä¸º 83920)\")\n",
    "\n",
    "# 3. [å·²ä¿®æ”¹] è·³è¿‡è·¯å¾„ä¿®æ­£æ­¥éª¤\n",
    "print(\">>>ä»¥æ­¤é…ç½®è·³è¿‡è·¯å¾„ä¿®æ”¹ï¼Œä¿ç•™ CSV ä¸­çš„åŸå§‹è·¯å¾„ string...\")\n",
    "# åŸæœ‰çš„ fix_path é€»è¾‘å·²è¢«ç§»é™¤ï¼Œdf_clean[col] ä¿æŒä¸å˜\n",
    "\n",
    "# 4. æœ€ç»ˆéªŒè¯ (é€»è¾‘è°ƒæ•´)\n",
    "# æ—¢ç„¶ CSV é‡Œçš„è·¯å¾„å’Œç¡¬ç›˜ä¸Šçš„ä¸ä¸€è‡´ï¼ˆåç¼€/ç›®å½•ä¸åŒï¼‰ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥æ£€æŸ¥ CSV è·¯å¾„ã€‚\n",
    "# æˆ‘ä»¬æ£€æŸ¥ï¼šCSV é‡Œæåˆ°çš„è¿™ä¸ª stemï¼Œåœ¨ REAL_WAV_DIR é‡Œæœ‰æ²¡æœ‰å¯¹åº”çš„ .wav æ–‡ä»¶ï¼Ÿ\n",
    "print(\">>> æ­£åœ¨éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (åŸºäº stem åŒ¹é…)...\")\n",
    "\n",
    "def check_real_file_exists(stem):\n",
    "    # æ— è®º CSV é‡Œå†™åœ¨å“ªï¼Œæˆ‘ä»¬éƒ½å» REAL_WAV_DIR é‡Œæ‰¾å¯¹åº”çš„ .wav\n",
    "    target_file = REAL_WAV_DIR / f\"{stem}.wav\"\n",
    "    return target_file.exists()\n",
    "\n",
    "exists_mask = df_clean['stem'].apply(check_real_file_exists)\n",
    "valid_count = exists_mask.sum()\n",
    "\n",
    "if valid_count == len(df_clean):\n",
    "    print(f\"âœ… å®Œç¾ï¼å»é‡åçš„ {valid_count} æ¡è®°å½•åœ¨çœŸå®ç›®å½•ä¸‹éƒ½èƒ½æ‰¾åˆ°å¯¹åº”çš„ .wav æ–‡ä»¶ã€‚\")\n",
    "else:\n",
    "    print(f\"âŒ è­¦å‘Šï¼šæœ‰ {len(df_clean) - valid_count} æ¡è®°å½•åœ¨çœŸå®ç›®å½•ä¸‹æ‰¾ä¸åˆ°å¯¹åº”çš„ .wav æ–‡ä»¶ï¼\")\n",
    "    # å¦‚æœæ‰¾ä¸åˆ°çœŸå®æ–‡ä»¶ï¼Œå»ºè®®è¿˜æ˜¯å‰”é™¤ï¼Œå¦åˆ™è®­ç»ƒå¿…æŠ¥é”™\n",
    "    # å¦‚æœä½ ç¡®å®šä¸æƒ³å‰”é™¤ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ\n",
    "    df_clean = df_clean[exists_mask]\n",
    "\n",
    "# 5. æ¸…ç†ä¸´æ—¶åˆ—å¹¶ä¿å­˜\n",
    "df_clean.drop(columns=['stem'], inplace=True)\n",
    "# encoding='utf-8-sig' é˜²æ­¢ä¸­æ–‡ä¹±ç \n",
    "df_clean.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig') \n",
    "\n",
    "print(f\"\\nå·²ä¿å­˜æœ€ç»ˆæ–‡ä»¶åˆ°: {OUTPUT_CSV_PATH}\")\n",
    "print(f\"æ³¨æ„ï¼šç”Ÿæˆçš„ CSV ä¸­ '{col}' åˆ—ä¾ç„¶ä¿æŒåŸå§‹æ ¼å¼ (å¦‚ .pt åç¼€æˆ–æ—§ç›¸å¯¹è·¯å¾„)ã€‚\")\n",
    "print(\"è¯·ç¡®ä¿ä½ çš„ Dataset/DataLoader ä»£ç èƒ½æ­£ç¡®å¤„ç†è¿™äº›è·¯å¾„ï¼ˆä¾‹å¦‚æ‰‹åŠ¨æ‹¼æ¥ root ç›®å½•æˆ–æ›¿æ¢åç¼€ï¼‰ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1bdbf",
   "metadata": {},
   "source": [
    "# Testæ–‡ä»¶å¤¹æ ‡æ³¨å»é‡å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ‡æ³¨åˆ—åï¼š ['wav_path', 'label', 'text_path']\n",
      "æ ‡æ³¨ä¸­å…±æœ‰ 15450 æ¡è®°å½•ï¼Œ15155 ä¸ªå”¯ä¸€ stemã€‚\n",
      "X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_test ä¸‹å…±æ‰¾åˆ° 15155 ä¸ª wav æ–‡ä»¶ï¼Œ15155 ä¸ªå”¯ä¸€ stemã€‚\n",
      "\n",
      "[æ£€æŸ¥ç»“æœ]\n",
      "æ ‡æ³¨æœŸæœ›çš„ stem æ•°é‡: 15155\n",
      "å®é™… wav stem æ•°é‡: 15155\n",
      "ç¼ºå¤±çš„ wav æ•°é‡: 0\n",
      "å¤šä½™çš„ wav æ•°é‡: 0\n",
      "\n",
      "å‰ 10 ä¸ªç¼ºå¤±çš„ stemï¼š []\n",
      "å‰ 10 ä¸ªå¤šä½™çš„ stemï¼š []\n"
     ]
    }
   ],
   "source": [
    "# æ ‡æ³¨æ–‡ä»¶è·¯å¾„\n",
    "META_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_test.csv\")\n",
    "\n",
    "# wav æ‰€åœ¨æ ¹ç›®å½•\n",
    "WAV_ROOT = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_test\")\n",
    "\n",
    "# æ ‡æ³¨é‡Œè¡¨ç¤ºéŸ³é¢‘è·¯å¾„çš„åˆ—å\n",
    "WAV_COL_NAME = \"wav_path\"\n",
    "\n",
    "# è¯»å–æ ‡æ³¨æ–‡ä»¶\n",
    "df = pd.read_csv(META_CSV)\n",
    "print(\"æ ‡æ³¨åˆ—åï¼š\", list(df.columns))\n",
    "assert WAV_COL_NAME in df.columns, f\"åˆ— {WAV_COL_NAME} ä¸åœ¨æ ‡æ³¨æ–‡ä»¶ä¸­ï¼\"\n",
    "\n",
    "# æŠ½å– stemï¼ˆå»æ‰ç›®å½•å’Œåç¼€ï¼Œåªä¿ç•™ä¸»æ–‡ä»¶åï¼‰\n",
    "from pathlib import Path\n",
    "\n",
    "expected_stems = df[WAV_COL_NAME].astype(str).apply(lambda p: Path(p).stem)\n",
    "expected_stem_set = set(expected_stems.tolist())\n",
    "\n",
    "print(f\"æ ‡æ³¨ä¸­å…±æœ‰ {len(df)} æ¡è®°å½•ï¼Œ\"\n",
    "      f\"{len(expected_stem_set)} ä¸ªå”¯ä¸€ stemã€‚\")\n",
    "\n",
    "# æ‰«æç›®å½•ä¸‹æ‰€æœ‰ .wav\n",
    "wav_paths = list(WAV_ROOT.rglob(\"*.wav\"))\n",
    "actual_stem_set = {p.stem for p in wav_paths}\n",
    "\n",
    "print(f\"{WAV_ROOT} ä¸‹å…±æ‰¾åˆ° {len(wav_paths)} ä¸ª wav æ–‡ä»¶ï¼Œ\"\n",
    "      f\"{len(actual_stem_set)} ä¸ªå”¯ä¸€ stemã€‚\")\n",
    "\n",
    "# è®¡ç®—å·®é›†\n",
    "missing_stems = sorted(expected_stem_set - actual_stem_set)  # æ ‡æ³¨æœ‰ï¼Œç›®å½•æ²¡æœ‰\n",
    "extra_stems   = sorted(actual_stem_set - expected_stem_set)  # ç›®å½•æœ‰ï¼Œæ ‡æ³¨æ²¡æœ‰\n",
    "\n",
    "print(f\"\\n[æ£€æŸ¥ç»“æœ]\")\n",
    "print(f\"æ ‡æ³¨æœŸæœ›çš„ stem æ•°é‡: {len(expected_stem_set)}\")\n",
    "print(f\"å®é™… wav stem æ•°é‡: {len(actual_stem_set)}\")\n",
    "print(f\"ç¼ºå¤±çš„ wav æ•°é‡: {len(missing_stems)}\")\n",
    "print(f\"å¤šä½™çš„ wav æ•°é‡: {len(extra_stems)}\")\n",
    "\n",
    "print(\"\\nå‰ 10 ä¸ªç¼ºå¤±çš„ stemï¼š\", missing_stems[:10])\n",
    "print(\"å‰ 10 ä¸ªå¤šä½™çš„ stemï¼š\", extra_stems[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8c9fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€»è¡Œæ•°: 15450\n",
      "å”¯ä¸€ stem æ•°: 15155\n",
      "å‡ºç°è¶…è¿‡ 1 æ¬¡çš„ stem æ•°é‡: 295\n",
      "\n",
      "ç¤ºä¾‹ï¼šè¿™äº› stem åœ¨æ ‡æ³¨ä¸­å‡ºç°äº†å¤šæ¬¡ï¼š ['20210201T000447.782Z_12_id_5_typecargo_60_0', '20210131T055900.157Z_795_id_5_typecargo_31', '20210202T112011.517Z_1827_id_5_typecargo_53', '20210202T112133.917Z_1829_id_5_typecargo_31_0', '20210202T112602.957Z_1842_id_5_typecargo_51']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_path</th>\n",
       "      <th>label</th>\n",
       "      <th>text_path</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>./v100_preprocessed_89_09_31/20210131T055900.1...</td>\n",
       "      <td>Towing</td>\n",
       "      <td>./v100_preprocessed_89_09_31/20210131T055900.1...</td>\n",
       "      <td>20210131T055900.157Z_795_id_5_typecargo_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>./v100_preprocessed_89_09_31/20210201T000447.7...</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>./v100_preprocessed_89_09_31/20210201T000447.7...</td>\n",
       "      <td>20210201T000447.782Z_12_id_5_typecargo_60_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112011.5...</td>\n",
       "      <td>Port Tender</td>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112011.5...</td>\n",
       "      <td>20210202T112011.517Z_1827_id_5_typecargo_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112133.9...</td>\n",
       "      <td>Towing</td>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112133.9...</td>\n",
       "      <td>20210202T112133.917Z_1829_id_5_typecargo_31_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112602.9...</td>\n",
       "      <td>Search and Rescue vessel</td>\n",
       "      <td>./v100_preprocessed_89_09_31/20210202T112602.9...</td>\n",
       "      <td>20210202T112602.957Z_1842_id_5_typecargo_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>./3090latest_wav/20210131T055900.157Z_795_id_5...</td>\n",
       "      <td>Towing</td>\n",
       "      <td>./3090latest_wav/20210131T055900.157Z_795_id_5...</td>\n",
       "      <td>20210131T055900.157Z_795_id_5_typecargo_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14875</th>\n",
       "      <td>./3090latest_wav/20210201T000447.782Z_12_id_5_...</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>./3090latest_wav/20210201T000447.782Z_12_id_5_...</td>\n",
       "      <td>20210201T000447.782Z_12_id_5_typecargo_60_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15411</th>\n",
       "      <td>./3090latest_wav/20210202T112011.517Z_1827_id_...</td>\n",
       "      <td>Port Tender</td>\n",
       "      <td>./3090latest_wav/20210202T112011.517Z_1827_id_...</td>\n",
       "      <td>20210202T112011.517Z_1827_id_5_typecargo_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15413</th>\n",
       "      <td>./3090latest_wav/20210202T112133.917Z_1829_id_...</td>\n",
       "      <td>Towing</td>\n",
       "      <td>./3090latest_wav/20210202T112133.917Z_1829_id_...</td>\n",
       "      <td>20210202T112133.917Z_1829_id_5_typecargo_31_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15414</th>\n",
       "      <td>./3090latest_wav/20210202T112602.957Z_1842_id_...</td>\n",
       "      <td>Search and Rescue vessel</td>\n",
       "      <td>./3090latest_wav/20210202T112602.957Z_1842_id_...</td>\n",
       "      <td>20210202T112602.957Z_1842_id_5_typecargo_51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                wav_path  \\\n",
       "6267   ./v100_preprocessed_89_09_31/20210131T055900.1...   \n",
       "6625   ./v100_preprocessed_89_09_31/20210201T000447.7...   \n",
       "7280   ./v100_preprocessed_89_09_31/20210202T112011.5...   \n",
       "7281   ./v100_preprocessed_89_09_31/20210202T112133.9...   \n",
       "7282   ./v100_preprocessed_89_09_31/20210202T112602.9...   \n",
       "14351  ./3090latest_wav/20210131T055900.157Z_795_id_5...   \n",
       "14875  ./3090latest_wav/20210201T000447.782Z_12_id_5_...   \n",
       "15411  ./3090latest_wav/20210202T112011.517Z_1827_id_...   \n",
       "15413  ./3090latest_wav/20210202T112133.917Z_1829_id_...   \n",
       "15414  ./3090latest_wav/20210202T112602.957Z_1842_id_...   \n",
       "\n",
       "                          label  \\\n",
       "6267                     Towing   \n",
       "6625                  Passenger   \n",
       "7280                Port Tender   \n",
       "7281                     Towing   \n",
       "7282   Search and Rescue vessel   \n",
       "14351                    Towing   \n",
       "14875                 Passenger   \n",
       "15411               Port Tender   \n",
       "15413                    Towing   \n",
       "15414  Search and Rescue vessel   \n",
       "\n",
       "                                               text_path  \\\n",
       "6267   ./v100_preprocessed_89_09_31/20210131T055900.1...   \n",
       "6625   ./v100_preprocessed_89_09_31/20210201T000447.7...   \n",
       "7280   ./v100_preprocessed_89_09_31/20210202T112011.5...   \n",
       "7281   ./v100_preprocessed_89_09_31/20210202T112133.9...   \n",
       "7282   ./v100_preprocessed_89_09_31/20210202T112602.9...   \n",
       "14351  ./3090latest_wav/20210131T055900.157Z_795_id_5...   \n",
       "14875  ./3090latest_wav/20210201T000447.782Z_12_id_5_...   \n",
       "15411  ./3090latest_wav/20210202T112011.517Z_1827_id_...   \n",
       "15413  ./3090latest_wav/20210202T112133.917Z_1829_id_...   \n",
       "15414  ./3090latest_wav/20210202T112602.957Z_1842_id_...   \n",
       "\n",
       "                                                stem  \n",
       "6267      20210131T055900.157Z_795_id_5_typecargo_31  \n",
       "6625     20210201T000447.782Z_12_id_5_typecargo_60_0  \n",
       "7280     20210202T112011.517Z_1827_id_5_typecargo_53  \n",
       "7281   20210202T112133.917Z_1829_id_5_typecargo_31_0  \n",
       "7282     20210202T112602.957Z_1842_id_5_typecargo_51  \n",
       "14351     20210131T055900.157Z_795_id_5_typecargo_31  \n",
       "14875    20210201T000447.782Z_12_id_5_typecargo_60_0  \n",
       "15411    20210202T112011.517Z_1827_id_5_typecargo_53  \n",
       "15413  20210202T112133.917Z_1829_id_5_typecargo_31_0  \n",
       "15414    20210202T112602.957Z_1842_id_5_typecargo_51  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "META_CSV = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_test.csv\")\n",
    "df = pd.read_csv(META_CSV)\n",
    "\n",
    "# å– stem\n",
    "df[\"stem\"] = df[\"wav_path\"].astype(str).apply(lambda p: Path(p).stem)\n",
    "\n",
    "# ç»Ÿè®¡æ¯ä¸ª stem å‡ºç°æ¬¡æ•°\n",
    "counts = df[\"stem\"].value_counts()\n",
    "\n",
    "print(\"æ€»è¡Œæ•°:\", len(df))\n",
    "print(\"å”¯ä¸€ stem æ•°:\", counts.shape[0])\n",
    "print(\"å‡ºç°è¶…è¿‡ 1 æ¬¡çš„ stem æ•°é‡:\", (counts > 1).sum())\n",
    "\n",
    "# çœ‹çœ‹å‰å‡ ä¸ªé‡å¤çš„ä¾‹å­\n",
    "dup_examples = counts[counts > 1].head(5).index.tolist()\n",
    "print(\"\\nç¤ºä¾‹ï¼šè¿™äº› stem åœ¨æ ‡æ³¨ä¸­å‡ºç°äº†å¤šæ¬¡ï¼š\", dup_examples)\n",
    "\n",
    "df_dup = df[df[\"stem\"].isin(dup_examples)]\n",
    "df_dup.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46aa154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸæ ‡æ³¨åˆ—åï¼š ['wav_path', 'label', 'text_path']\n",
      "åŸæ ‡æ³¨è¡Œæ•°ï¼š 15450\n",
      "å®é™… wav æ•°é‡ï¼š 15155\n",
      "å®é™…å”¯ä¸€ stem æ•°é‡ï¼š 15155\n",
      "ä¸ wav åŒ¹é…åçš„æ ‡æ³¨è¡Œæ•°ï¼š 15450\n",
      "å»é‡åçš„æ ‡æ³¨è¡Œæ•°ï¼š 15155\n",
      "å·²ä¿å­˜å»é‡åçš„æ ‡æ³¨æ–‡ä»¶åˆ°ï¼šX:\\æ•°æ®é›†\\OceanShip_2\\oceanship_full_test_dedup.csv\n"
     ]
    }
   ],
   "source": [
    "# 2. è¯»å–æ ‡æ³¨ï¼Œå¢åŠ  stem åˆ—ï¼ˆå»æ‰ç›®å½•å’Œåç¼€ï¼‰\n",
    "df = pd.read_csv(META_CSV)\n",
    "print(\"åŸæ ‡æ³¨åˆ—åï¼š\", list(df.columns))\n",
    "print(\"åŸæ ‡æ³¨è¡Œæ•°ï¼š\", len(df))\n",
    "\n",
    "df[\"stem\"] = df[\"wav_path\"].astype(str).apply(lambda p: Path(p).stem)\n",
    "\n",
    "# 3. æ‰«æå®é™…å­˜åœ¨çš„ wavï¼Œå¾—åˆ°åˆæ³• stem é›†åˆ\n",
    "wav_paths = list(WAV_ROOT.rglob(\"*.wav\"))\n",
    "wav_stems = {p.stem for p in wav_paths}\n",
    "print(\"å®é™… wav æ•°é‡ï¼š\", len(wav_paths))\n",
    "print(\"å®é™…å”¯ä¸€ stem æ•°é‡ï¼š\", len(wav_stems))\n",
    "\n",
    "# 4. åªä¿ç•™â€œç¡®å®æœ‰å¯¹åº” wavâ€çš„æ ‡æ³¨è¡Œï¼ˆä¸€èˆ¬éƒ½ä¼šå…¨éƒ¨ä¿ç•™ï¼Œè¿™ä¸€æ­¥æ˜¯å®‰å…¨æ£€æŸ¥ï¼‰\n",
    "df_valid = df[df[\"stem\"].isin(wav_stems)].copy()\n",
    "print(\"ä¸ wav åŒ¹é…åçš„æ ‡æ³¨è¡Œæ•°ï¼š\", len(df_valid))\n",
    "\n",
    "# 5. æŒ‰ stem å»é‡ï¼šåŒä¸€ä¸ª wav åªä¿ç•™ä¸€è¡Œæ ‡æ³¨\n",
    "#    è¿™é‡Œ keep='first' è¡¨ç¤ºä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„é‚£ä¸€æ¡ï¼Œä½ ä¹Ÿå¯ä»¥æ”¹æˆ 'last'\n",
    "df_dedup = (\n",
    "    df_valid\n",
    "    .sort_values(\"stem\")             # å…ˆæŒ‰ stem æ’ä¸€ä¸‹\n",
    "    .drop_duplicates(\"stem\", keep=\"first\")\n",
    ")\n",
    "\n",
    "print(\"å»é‡åçš„æ ‡æ³¨è¡Œæ•°ï¼š\", len(df_dedup))\n",
    "\n",
    "# 6. å»æ‰ä¸´æ—¶çš„ stem åˆ—ï¼Œä¿å­˜ä¸ºæ–°çš„ csv\n",
    "out_csv = META_CSV.with_name(META_CSV.stem + \"_dedup.csv\")\n",
    "df_dedup.drop(columns=[\"stem\"]).to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"å·²ä¿å­˜å»é‡åçš„æ ‡æ³¨æ–‡ä»¶åˆ°ï¼š{out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3726037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨ X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_test ä¸‹å…±æ‰¾åˆ° 15155 ä¸ª wav æ–‡ä»¶.\n",
      "\n",
      "å‡†å¤‡æ£€æŸ¥ 10 ä¸ªæ–‡ä»¶çš„é‡‡æ ·ç‡ã€é€šé“æ•°å’Œæ—¶é•¿ï¼š\n",
      "\n",
      "[1] 20210106T010452.131Z_134_id_5_typecargo_60_0.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 160000\n",
      "    æ—¶é•¿ (duration)     : 5.000 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[2] 20201205T033704.303Z_437_id_5_typecargo_52_1.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 160000\n",
      "    æ—¶é•¿ (duration)     : 5.000 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[3] 20200814T000035.853Z_1_id_5_typecargo_52_2.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 76416\n",
      "    æ—¶é•¿ (duration)     : 2.388 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[4] 20201028T055212.450Z_693_id_5_typecargo_31_1.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 160000\n",
      "    æ—¶é•¿ (duration)     : 5.000 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[5] 20210202T003618.717Z_85_id_5_typecargo_53_0.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 160000\n",
      "    æ—¶é•¿ (duration)     : 5.000 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[6] 20200917T073140.732Z_1056_id_24_typecargo_36.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 82784\n",
      "    æ—¶é•¿ (duration)     : 2.587 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[7] 20201026T014639.170Z_244_id_5_typecargo_32.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 119520\n",
      "    æ—¶é•¿ (duration)     : 3.735 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[8] 20200919T092640.698Z_1280_id_5_typecargo_31.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 155328\n",
      "    æ—¶é•¿ (duration)     : 4.854 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[9] 20210117T135318.928Z_1694_id_5_typecargo_52.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 80224\n",
      "    æ—¶é•¿ (duration)     : 2.507 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n",
      "[10] 20201026T134556.394Z_1798_id_5_typecargo_31_0.wav\n",
      "    é‡‡æ ·ç‡ (sample rate): 32000 Hz\n",
      "    é€šé“æ•° (channels)   : 1\n",
      "    æ ·æœ¬ç‚¹æ•° (samples)  : 160000\n",
      "    æ—¶é•¿ (duration)     : 5.000 ç§’\n",
      "    æ•°æ®ç±»å‹ (dtype)    : float64\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. é…ç½®ä½ çš„ test éŸ³é¢‘ç›®å½•\n",
    "WAV_ROOT = Path(r\"X:\\æ•°æ®é›†\\OceanShip_2\\Oceanship_test\")\n",
    "\n",
    "# 2. æ”¶é›†æ‰€æœ‰ wav æ–‡ä»¶\n",
    "wav_paths = sorted(WAV_ROOT.rglob(\"*.wav\"))\n",
    "print(f\"åœ¨ {WAV_ROOT} ä¸‹å…±æ‰¾åˆ° {len(wav_paths)} ä¸ª wav æ–‡ä»¶.\")\n",
    "\n",
    "if len(wav_paths) == 0:\n",
    "    raise RuntimeError(\"æ²¡æœ‰æ‰¾åˆ° wav æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ WAV_ROOT è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚\")\n",
    "\n",
    "# 3. éšæœºæŠ½å– 10 ä¸ªï¼ˆå¦‚æœæ€»æ•°å°äº 10ï¼Œå°±å…¨æµ‹ï¼‰\n",
    "N = 10\n",
    "if len(wav_paths) <= N:\n",
    "    sample_paths = wav_paths\n",
    "else:\n",
    "    sample_paths = random.sample(wav_paths, N)\n",
    "\n",
    "print(f\"\\nå‡†å¤‡æ£€æŸ¥ {len(sample_paths)} ä¸ªæ–‡ä»¶çš„é‡‡æ ·ç‡ã€é€šé“æ•°å’Œæ—¶é•¿ï¼š\\n\")\n",
    "\n",
    "# 4. é€ä¸ªè¯»å–å¹¶æ‰“å°ä¿¡æ¯\n",
    "for i, p in enumerate(sample_paths, start=1):\n",
    "    data, sr = sf.read(p)  # data: numpy array, sr: sample rate\n",
    "    # é€šé“æ•°\n",
    "    if data.ndim == 1:\n",
    "        channels = 1\n",
    "        num_samples = data.shape[0]\n",
    "    else:\n",
    "        channels = data.shape[1]\n",
    "        num_samples = data.shape[0]\n",
    "\n",
    "    duration_sec = num_samples / sr\n",
    "\n",
    "    print(f\"[{i}] {p.name}\")\n",
    "    print(f\"    é‡‡æ ·ç‡ (sample rate): {sr} Hz\")\n",
    "    print(f\"    é€šé“æ•° (channels)   : {channels}\")\n",
    "    print(f\"    æ ·æœ¬ç‚¹æ•° (samples)  : {num_samples}\")\n",
    "    print(f\"    æ—¶é•¿ (duration)     : {duration_sec:.3f} ç§’\")\n",
    "    print(f\"    æ•°æ®ç±»å‹ (dtype)    : {data.dtype}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5387060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€»æ–‡ä»¶æ•°: 15155\n",
      "ä¸è¶³ 5s çš„æ•°é‡: 8370\n",
      "ä¸è¶³ 5s çš„æ¯”ä¾‹: 55.23%\n"
     ]
    }
   ],
   "source": [
    "TARGET_SR = 32000\n",
    "TARGET_DUR = 5.0\n",
    "TARGET_LEN = int(TARGET_SR * TARGET_DUR) \n",
    "\n",
    "lengths = []\n",
    "for p in WAV_ROOT.rglob(\"*.wav\"):\n",
    "    data, sr = sf.read(str(p))\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    lengths.append(len(data))\n",
    "\n",
    "lengths = np.array(lengths)\n",
    "short = (lengths < TARGET_LEN)\n",
    "print(\"æ€»æ–‡ä»¶æ•°:\", len(lengths))\n",
    "print(\"ä¸è¶³ 5s çš„æ•°é‡:\", short.sum())\n",
    "print(\"ä¸è¶³ 5s çš„æ¯”ä¾‹: {:.2f}%\".format(short.mean() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
