{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa985e7",
   "metadata": {},
   "source": [
    "# æ•°æ®é›†çš„åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd62f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c48a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ ‡æ³¨æ–‡ä»¶è·¯å¾„ (è¯·ç¡®ä¿è¿™æ˜¯åŒ…å« dataset_split åˆ—çš„æ–‡ä»¶)\n",
    "csv_path = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata_add_Environmental_Noise.csv\"\n",
    "# è¾“å…¥éŸ³é¢‘æ–‡ä»¶ç›®å½•\n",
    "SOURCE_ROOT = r\"X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\"\n",
    "\n",
    "# è¾“å‡ºç›®å½• (ç¨‹åºä¼šè‡ªåŠ¨åˆ›å»º train å’Œ test æ–‡ä»¶å¤¹)\n",
    "OUTPUT_ROOT = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489d4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_file_index(root_path):\n",
    "    \"\"\"\n",
    "    ä¸ç®¡æ–‡ä»¶æ˜¯åœ¨ Cargo/0_1.wav è¿˜æ˜¯ Background/test/3_0/0000/4_0_1.wav\n",
    "    åªè¦åœ¨è¿™ä¸ªæ ¹ç›®å½•ä¸‹ï¼Œéƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ã€‚\n",
    "    è¿”å›å­—å…¸: {'æ–‡ä»¶å': 'å®Œæ•´ç»å¯¹è·¯å¾„'}\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: {root_path}\")\n",
    "    print(\"   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\")\n",
    "    \n",
    "    file_map = {}\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                # è®°å½•: æ–‡ä»¶å -> å®Œæ•´è·¯å¾„\n",
    "                file_map[file] = os.path.join(root, file)\n",
    "                count += 1\n",
    "                \n",
    "    print(f\"âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° {count} ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\")\n",
    "    return file_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_unified():\n",
    "    # è¯»å– CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ° CSV æ–‡ä»¶ {csv_path}\")\n",
    "        return\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # åªå¤„ç† train å’Œ test\n",
    "    df_valid = df[df['dataset_split'].isin(['train', 'test'])]\n",
    "    print(f\"ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: {len(df_valid)}\")\n",
    "\n",
    "    # å»ºç«‹æ–‡ä»¶ç´¢å¼• (è§£å†³è·¯å¾„æ·±æµ…ä¸ä¸€çš„é—®é¢˜)\n",
    "    file_index = build_file_index(SOURCE_ROOT)\n",
    "    \n",
    "    if len(file_index) == 0:\n",
    "        print(\"âŒ ä¸¥é‡é”™è¯¯: æºç›®å½•ä¸‹æ²¡æœ‰æ‰«æåˆ°ä»»ä½• .wav æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "        return\n",
    "\n",
    "    # 3.3 ç±»åˆ«æ˜ å°„\n",
    "    id_to_folder = {\n",
    "        0: 'Cargo', \n",
    "        1: 'Passengership', \n",
    "        2: 'Tanker', \n",
    "        3: 'Tug', \n",
    "        4: 'Background'\n",
    "    }\n",
    "\n",
    "    success_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for index, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Splitting\"):\n",
    "        class_id = row['class_id']\n",
    "        filename = row['new_filename'] # ä¾‹å¦‚ 0_1.wav æˆ– 4_0_1.wav\n",
    "        split = row['dataset_split']   # train æˆ– test\n",
    "        \n",
    "        # è·å–ç›®æ ‡å­æ–‡ä»¶å¤¹å\n",
    "        folder_name = id_to_folder.get(class_id)\n",
    "        if not folder_name: continue\n",
    "\n",
    "        # --- A. æŸ¥æ‰¾æºæ–‡ä»¶ (Source) ---\n",
    "        # ç›´æ¥æŸ¥å­—å…¸ï¼Œä¸ç”¨ç®¡å®ƒåœ¨å“ªä¸ªå­æ–‡ä»¶å¤¹é‡Œ\n",
    "        src_path = file_index.get(filename)\n",
    "        \n",
    "        if not src_path:\n",
    "            # å­—å…¸é‡Œæ²¡æŸ¥åˆ°ï¼Œè¯´æ˜æ–‡ä»¶çœŸçš„ä¸å­˜åœ¨\n",
    "            missing_count += 1\n",
    "            if missing_count <= 5: # åªæ‰“å°å‰5ä¸ªé”™è¯¯ï¼Œé˜²æ­¢åˆ·å±\n",
    "                print(f\"âš ï¸ ç¼ºå¤±: æ‰¾ä¸åˆ°æ–‡ä»¶ {filename}\")\n",
    "            continue\n",
    "\n",
    "        # --- B. è®¾å®šç›®æ ‡è·¯å¾„ (Destination) ---\n",
    "        # å¼ºåˆ¶ç»“æ„: Output / split / Category / filename\n",
    "        dst_dir = os.path.join(OUTPUT_ROOT, split, folder_name)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "        # --- C. å¤åˆ¶æ–‡ä»¶ ---\n",
    "        try:\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å¤åˆ¶å¤±è´¥ {filename}: {e}\")\n",
    "\n",
    "    # ================= 4. ç»“æœç»Ÿè®¡ =================\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"âœ… æˆåŠŸå¤åˆ¶: {success_count}\")\n",
    "    print(f\"âŒ æ–‡ä»¶ç¼ºå¤±: {missing_count}\")\n",
    "    print(f\"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_ROOT}\")\n",
    "    \n",
    "    # æ‰“å°ç›®å½•ç»“æ„ç¡®è®¤\n",
    "    print(\"\\nç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\")\n",
    "    if success_count > 0:\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\train\\\\Cargo\\\\0_1.wav\")\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\test\\\\Background\\\\4_0_1.wav\")\n",
    "        print(\"  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615cdb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: 28377\n",
      "ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\n",
      "   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\n",
      "âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° 28377 ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28377/28377 [03:30<00:00, 135.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "å¤„ç†å®Œæˆï¼\n",
      "âœ… æˆåŠŸå¤åˆ¶: 28377\n",
      "âŒ æ–‡ä»¶ç¼ºå¤±: 0\n",
      "ğŸ“‚ è¾“å‡ºç›®å½•: X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\n",
      "\n",
      "ç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\train\\Cargo\\0_1.wav\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\test\\Background\\4_0_1.wav\n",
      "  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "split_dataset_unified()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
