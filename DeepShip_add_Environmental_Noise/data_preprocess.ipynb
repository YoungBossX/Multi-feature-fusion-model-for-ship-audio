{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa985e7",
   "metadata": {},
   "source": [
    "# æ•°æ®é›†çš„åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbd62f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.io.wavfile as wavfile\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c48a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ ‡æ³¨æ–‡ä»¶è·¯å¾„ (è¯·ç¡®ä¿è¿™æ˜¯åŒ…å« dataset_split åˆ—çš„æ–‡ä»¶)\n",
    "csv_path = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata_add_Environmental_Noise.csv\"\n",
    "# è¾“å…¥éŸ³é¢‘æ–‡ä»¶ç›®å½•\n",
    "SOURCE_ROOT = r\"X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\"\n",
    "\n",
    "# è¾“å‡ºç›®å½• (ç¨‹åºä¼šè‡ªåŠ¨åˆ›å»º train å’Œ test æ–‡ä»¶å¤¹)\n",
    "OUTPUT_ROOT = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489d4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_file_index(root_path):\n",
    "    \"\"\"\n",
    "    ä¸ç®¡æ–‡ä»¶æ˜¯åœ¨ Cargo/0_1.wav è¿˜æ˜¯ Background/test/3_0/0000/4_0_1.wav\n",
    "    åªè¦åœ¨è¿™ä¸ªæ ¹ç›®å½•ä¸‹ï¼Œéƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ã€‚\n",
    "    è¿”å›å­—å…¸: {'æ–‡ä»¶å': 'å®Œæ•´ç»å¯¹è·¯å¾„'}\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: {root_path}\")\n",
    "    print(\"   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\")\n",
    "    \n",
    "    file_map = {}\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                # è®°å½•: æ–‡ä»¶å -> å®Œæ•´è·¯å¾„\n",
    "                file_map[file] = os.path.join(root, file)\n",
    "                count += 1\n",
    "                \n",
    "    print(f\"âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° {count} ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\")\n",
    "    return file_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_unified():\n",
    "    # è¯»å– CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ° CSV æ–‡ä»¶ {csv_path}\")\n",
    "        return\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # åªå¤„ç† train å’Œ test\n",
    "    df_valid = df[df['dataset_split'].isin(['train', 'test'])]\n",
    "    print(f\"ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: {len(df_valid)}\")\n",
    "\n",
    "    # å»ºç«‹æ–‡ä»¶ç´¢å¼• (è§£å†³è·¯å¾„æ·±æµ…ä¸ä¸€çš„é—®é¢˜)\n",
    "    file_index = build_file_index(SOURCE_ROOT)\n",
    "    \n",
    "    if len(file_index) == 0:\n",
    "        print(\"âŒ ä¸¥é‡é”™è¯¯: æºç›®å½•ä¸‹æ²¡æœ‰æ‰«æåˆ°ä»»ä½• .wav æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "        return\n",
    "\n",
    "    # 3.3 ç±»åˆ«æ˜ å°„\n",
    "    id_to_folder = {\n",
    "        0: 'Cargo', \n",
    "        1: 'Passengership', \n",
    "        2: 'Tanker', \n",
    "        3: 'Tug', \n",
    "        4: 'Background'\n",
    "    }\n",
    "\n",
    "    success_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for index, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Splitting\"):\n",
    "        class_id = row['class_id']\n",
    "        filename = row['new_filename'] # ä¾‹å¦‚ 0_1.wav æˆ– 4_0_1.wav\n",
    "        split = row['dataset_split']   # train æˆ– test\n",
    "        \n",
    "        # è·å–ç›®æ ‡å­æ–‡ä»¶å¤¹å\n",
    "        folder_name = id_to_folder.get(class_id)\n",
    "        if not folder_name: continue\n",
    "\n",
    "        # --- A. æŸ¥æ‰¾æºæ–‡ä»¶ (Source) ---\n",
    "        # ç›´æ¥æŸ¥å­—å…¸ï¼Œä¸ç”¨ç®¡å®ƒåœ¨å“ªä¸ªå­æ–‡ä»¶å¤¹é‡Œ\n",
    "        src_path = file_index.get(filename)\n",
    "        \n",
    "        if not src_path:\n",
    "            # å­—å…¸é‡Œæ²¡æŸ¥åˆ°ï¼Œè¯´æ˜æ–‡ä»¶çœŸçš„ä¸å­˜åœ¨\n",
    "            missing_count += 1\n",
    "            if missing_count <= 5: # åªæ‰“å°å‰5ä¸ªé”™è¯¯ï¼Œé˜²æ­¢åˆ·å±\n",
    "                print(f\"âš ï¸ ç¼ºå¤±: æ‰¾ä¸åˆ°æ–‡ä»¶ {filename}\")\n",
    "            continue\n",
    "\n",
    "        # --- B. è®¾å®šç›®æ ‡è·¯å¾„ (Destination) ---\n",
    "        # å¼ºåˆ¶ç»“æ„: Output / split / Category / filename\n",
    "        dst_dir = os.path.join(OUTPUT_ROOT, split, folder_name)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "        # --- C. å¤åˆ¶æ–‡ä»¶ ---\n",
    "        try:\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å¤åˆ¶å¤±è´¥ {filename}: {e}\")\n",
    "\n",
    "    # ================= 4. ç»“æœç»Ÿè®¡ =================\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"âœ… æˆåŠŸå¤åˆ¶: {success_count}\")\n",
    "    print(f\"âŒ æ–‡ä»¶ç¼ºå¤±: {missing_count}\")\n",
    "    print(f\"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_ROOT}\")\n",
    "    \n",
    "    # æ‰“å°ç›®å½•ç»“æ„ç¡®è®¤\n",
    "    print(\"\\nç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\")\n",
    "    if success_count > 0:\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\train\\\\Cargo\\\\0_1.wav\")\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\test\\\\Background\\\\4_0_1.wav\")\n",
    "        print(\"  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615cdb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: 28377\n",
      "ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\n",
      "   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\n",
      "âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° 28377 ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28377/28377 [03:30<00:00, 135.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "å¤„ç†å®Œæˆï¼\n",
      "âœ… æˆåŠŸå¤åˆ¶: 28377\n",
      "âŒ æ–‡ä»¶ç¼ºå¤±: 0\n",
      "ğŸ“‚ è¾“å‡ºç›®å½•: X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\n",
      "\n",
      "ç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\train\\Cargo\\0_1.wav\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\test\\Background\\4_0_1.wav\n",
      "  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "split_dataset_unified()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb50296",
   "metadata": {},
   "source": [
    "# å› ä¸ºå™ªå£°ç±»å·²ç»åˆ‡å‰²è¿‡äº†ï¼Œæ‰€ä»¥ä¸åšåˆ‡å‰²å¤„ç†ï¼Œç­‰å…¶å®ƒç±»åšäº†åˆ‡å‰²åå†ä¸€èµ·åšé¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a47393",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\")\n",
    "OUTPUT_ROOT = Path(r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split_preprocessed\")\n",
    "\n",
    "# éŸ³é¢‘å‚æ•°\n",
    "FRAME_DURATION = 3.0   # åˆ‡ç‰‡æ—¶é•¿ 3ç§’\n",
    "OVERLAP_RATE = 0.0     # 0é‡å \n",
    "TARGET_SR = 32000      # ç›®æ ‡é‡‡æ ·ç‡\n",
    "TARGET_RMS = 0.05      # ç›®æ ‡ RMS å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mean(frame: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"å»ä¸­å¿ƒåŒ–: ç§»é™¤ç›´æµåˆ†é‡\"\"\"\n",
    "    return frame - np.mean(frame)\n",
    "\n",
    "def rms_normalize(frame: np.ndarray, target_rms: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"RMS å½’ä¸€åŒ–\"\"\"\n",
    "    rms = np.sqrt(np.mean(frame ** 2) + 1e-12)\n",
    "    if rms < 1e-8:\n",
    "        # å¦‚æœæ˜¯é™éŸ³ç‰‡æ®µï¼Œç›´æ¥è¿”å›å…¨0\n",
    "        return np.zeros_like(frame)\n",
    "    scale = target_rms / rms\n",
    "    return frame * scale\n",
    "\n",
    "def process_and_save(audio_data, save_path, sr):\n",
    "    \"\"\"ç»Ÿä¸€çš„åå¤„ç†æµæ°´çº¿ï¼šå»ä¸­å¿ƒåŒ– -> å½’ä¸€åŒ– -> ä¿å­˜\"\"\"\n",
    "    # å»ä¸­å¿ƒåŒ–\n",
    "    audio_data = remove_mean(audio_data)\n",
    "    \n",
    "    # å½’ä¸€åŒ–\n",
    "    audio_data = rms_normalize(audio_data, target_rms=TARGET_RMS)\n",
    "    \n",
    "    # ä¿å­˜ (float32)\n",
    "    wavfile.write(save_path, sr, audio_data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01c9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_smart_resample():\n",
    "    if not INPUT_ROOT.exists():\n",
    "        print(f\"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ {INPUT_ROOT}\")\n",
    "        return\n",
    "\n",
    "    # éå† train å’Œ test\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        split_in_dir = INPUT_ROOT / split\n",
    "        split_out_dir = OUTPUT_ROOT / split\n",
    "        \n",
    "        if not split_in_dir.exists():\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: {split} ...\")\n",
    "\n",
    "        # è·å–å½“å‰åˆ’åˆ†ä¸‹çš„æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹\n",
    "        categories = [d.name for d in split_in_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        for category in categories:\n",
    "            in_cat_dir = split_in_dir / category\n",
    "            out_cat_dir = split_out_dir / category\n",
    "            out_cat_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            wav_paths = sorted(list(in_cat_dir.glob(\"*.wav\")))\n",
    "            if not wav_paths:\n",
    "                continue\n",
    "            \n",
    "            print(f\"ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: {category} ({len(wav_paths)} ä¸ªæ–‡ä»¶)\")\n",
    "\n",
    "            # åˆ¤æ–­æ˜¯å¦ä¸ºèƒŒæ™¯å™ªå£°ç±»\n",
    "            is_noise_class = (category == \"Background\")\n",
    "\n",
    "            for wav_path in tqdm(wav_paths, desc=f\"     Processing {category}\", leave=False):\n",
    "                try:\n",
    "                    # å…ˆä½¿ç”¨ sr=None åŠ è½½ï¼Œè·å–åŸå§‹é‡‡æ ·ç‡\n",
    "                    audio, sr = librosa.load(wav_path, sr=None)\n",
    "                    \n",
    "                    # åªæœ‰å½“é‡‡æ ·ç‡ä¸åŒ¹é…æ—¶ï¼Œæ‰è¿›è¡Œé‡é‡‡æ ·\n",
    "                    if sr != TARGET_SR:\n",
    "                        print(f\"é‡é‡‡æ ·: {wav_path.name} ({sr}Hz -> {TARGET_SR}Hz)\")\n",
    "                        audio = librosa.resample(audio, orig_sr=sr, target_sr=TARGET_SR)\n",
    "                        sr = TARGET_SR\n",
    "                    \n",
    "                    file_stem = wav_path.stem \n",
    "                    \n",
    "                    # åœºæ™¯ A: èƒŒæ™¯å™ªå£°ç±» (ä¸åˆ‡å‰²)\n",
    "                    if is_noise_class:\n",
    "                        target_len = int(FRAME_DURATION * sr)\n",
    "                        if len(audio) < target_len:\n",
    "                            audio = np.pad(audio, (0, target_len - len(audio)), mode='constant')\n",
    "                        elif len(audio) > target_len:\n",
    "                            audio = audio[:target_len]\n",
    "                        \n",
    "                        save_name = f\"{file_stem}.wav\"\n",
    "                        process_and_save(audio, out_cat_dir / save_name, sr)\n",
    "\n",
    "                    # åœºæ™¯ B: èˆ¹åªç±» (åˆ‡å‰²ï¼Œé‡å‘½åä¸º X_X_1.wav)\n",
    "                    else:\n",
    "                        frame_length = int(FRAME_DURATION * sr)\n",
    "                        hop_length = int(frame_length * (1.0 - OVERLAP_RATE))\n",
    "                        \n",
    "                        if len(audio) < frame_length:\n",
    "                            audio = np.pad(audio, (0, frame_length - len(audio)), mode='constant')\n",
    "                        \n",
    "                        frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=hop_length).T\n",
    "                        \n",
    "                        # start=1: ç´¢å¼•ä»1å¼€å§‹\n",
    "                        for i, frame in enumerate(frames, start=1):\n",
    "                            save_name = f\"{file_stem}_{i}.wav\"\n",
    "                            process_and_save(frame, out_cat_dir / save_name, sr)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ å¤„ç†å‡ºé”™ {wav_path.name}: {e}\")\n",
    "\n",
    "    print(\"\\nâœ… æ‰€æœ‰æ–‡ä»¶é¢„å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {OUTPUT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad66a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: train ...\n",
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Background (19635 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Cargo (78 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Passengership (120 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tanker (158 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tug (42 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: test ...\n",
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Background (8133 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Cargo (31 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Passengership (71 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tanker (82 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tug (27 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ‰€æœ‰æ–‡ä»¶é¢„å¤„ç†å®Œæˆï¼\n",
      "è¾“å‡ºç›®å½•: X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\data_audio_rename_add_enviromental_noise_class_dataset_split_preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œå¤„ç†\n",
    "preprocess_dataset_smart_resample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
