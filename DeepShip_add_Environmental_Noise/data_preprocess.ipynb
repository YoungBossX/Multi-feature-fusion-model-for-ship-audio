{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa985e7",
   "metadata": {},
   "source": [
    "# æ•°æ®é›†çš„åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbd62f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import scipy.io.wavfile as wavfile\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c48a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ ‡æ³¨æ–‡ä»¶è·¯å¾„ (è¯·ç¡®ä¿è¿™æ˜¯åŒ…å« dataset_split åˆ—çš„æ–‡ä»¶)\n",
    "csv_path = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata_add_Environmental_Noise.csv\"\n",
    "# è¾“å…¥éŸ³é¢‘æ–‡ä»¶ç›®å½•\n",
    "SOURCE_ROOT = r\"X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\"\n",
    "\n",
    "# è¾“å‡ºç›®å½• (ç¨‹åºä¼šè‡ªåŠ¨åˆ›å»º train å’Œ test æ–‡ä»¶å¤¹)\n",
    "OUTPUT_ROOT = r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489d4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_file_index(root_path):\n",
    "    \"\"\"\n",
    "    ä¸ç®¡æ–‡ä»¶æ˜¯åœ¨ Cargo/0_1.wav è¿˜æ˜¯ Background/test/3_0/0000/4_0_1.wav\n",
    "    åªè¦åœ¨è¿™ä¸ªæ ¹ç›®å½•ä¸‹ï¼Œéƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ã€‚\n",
    "    è¿”å›å­—å…¸: {'æ–‡ä»¶å': 'å®Œæ•´ç»å¯¹è·¯å¾„'}\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: {root_path}\")\n",
    "    print(\"   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\")\n",
    "    \n",
    "    file_map = {}\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                # è®°å½•: æ–‡ä»¶å -> å®Œæ•´è·¯å¾„\n",
    "                file_map[file] = os.path.join(root, file)\n",
    "                count += 1\n",
    "                \n",
    "    print(f\"âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° {count} ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\")\n",
    "    return file_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_unified():\n",
    "    # è¯»å– CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ° CSV æ–‡ä»¶ {csv_path}\")\n",
    "        return\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # åªå¤„ç† train å’Œ test\n",
    "    df_valid = df[df['dataset_split'].isin(['train', 'test'])]\n",
    "    print(f\"ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: {len(df_valid)}\")\n",
    "\n",
    "    # å»ºç«‹æ–‡ä»¶ç´¢å¼• (è§£å†³è·¯å¾„æ·±æµ…ä¸ä¸€çš„é—®é¢˜)\n",
    "    file_index = build_file_index(SOURCE_ROOT)\n",
    "    \n",
    "    if len(file_index) == 0:\n",
    "        print(\"âŒ ä¸¥é‡é”™è¯¯: æºç›®å½•ä¸‹æ²¡æœ‰æ‰«æåˆ°ä»»ä½• .wav æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚\")\n",
    "        return\n",
    "\n",
    "    # 3.3 ç±»åˆ«æ˜ å°„\n",
    "    id_to_folder = {\n",
    "        0: 'Cargo', \n",
    "        1: 'Passengership', \n",
    "        2: 'Tanker', \n",
    "        3: 'Tug', \n",
    "        4: 'Background'\n",
    "    }\n",
    "\n",
    "    success_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for index, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Splitting\"):\n",
    "        class_id = row['class_id']\n",
    "        filename = row['new_filename'] # ä¾‹å¦‚ 0_1.wav æˆ– 4_0_1.wav\n",
    "        split = row['dataset_split']   # train æˆ– test\n",
    "        \n",
    "        # è·å–ç›®æ ‡å­æ–‡ä»¶å¤¹å\n",
    "        folder_name = id_to_folder.get(class_id)\n",
    "        if not folder_name: continue\n",
    "\n",
    "        # --- A. æŸ¥æ‰¾æºæ–‡ä»¶ (Source) ---\n",
    "        # ç›´æ¥æŸ¥å­—å…¸ï¼Œä¸ç”¨ç®¡å®ƒåœ¨å“ªä¸ªå­æ–‡ä»¶å¤¹é‡Œ\n",
    "        src_path = file_index.get(filename)\n",
    "        \n",
    "        if not src_path:\n",
    "            # å­—å…¸é‡Œæ²¡æŸ¥åˆ°ï¼Œè¯´æ˜æ–‡ä»¶çœŸçš„ä¸å­˜åœ¨\n",
    "            missing_count += 1\n",
    "            if missing_count <= 5: # åªæ‰“å°å‰5ä¸ªé”™è¯¯ï¼Œé˜²æ­¢åˆ·å±\n",
    "                print(f\"âš ï¸ ç¼ºå¤±: æ‰¾ä¸åˆ°æ–‡ä»¶ {filename}\")\n",
    "            continue\n",
    "\n",
    "        # --- B. è®¾å®šç›®æ ‡è·¯å¾„ (Destination) ---\n",
    "        # å¼ºåˆ¶ç»“æ„: Output / split / Category / filename\n",
    "        dst_dir = os.path.join(OUTPUT_ROOT, split, folder_name)\n",
    "        dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "        # --- C. å¤åˆ¶æ–‡ä»¶ ---\n",
    "        try:\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å¤åˆ¶å¤±è´¥ {filename}: {e}\")\n",
    "\n",
    "    # ================= 4. ç»“æœç»Ÿè®¡ =================\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"âœ… æˆåŠŸå¤åˆ¶: {success_count}\")\n",
    "    print(f\"âŒ æ–‡ä»¶ç¼ºå¤±: {missing_count}\")\n",
    "    print(f\"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_ROOT}\")\n",
    "    \n",
    "    # æ‰“å°ç›®å½•ç»“æ„ç¡®è®¤\n",
    "    print(\"\\nç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\")\n",
    "    if success_count > 0:\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\train\\\\Cargo\\\\0_1.wav\")\n",
    "        print(f\"  {OUTPUT_ROOT}\\\\test\\\\Background\\\\4_0_1.wav\")\n",
    "        print(\"  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615cdb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å¾…å¤„ç†ä»»åŠ¡æ€»æ•°: 28377\n",
      "ğŸ” æ­£åœ¨æ‰«ææºç›®å½•å»ºç«‹ç´¢å¼•: X:\\\\æ•°æ®é›†\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class\n",
      "   (å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ...)\n",
      "âœ… ç´¢å¼•å»ºç«‹å®Œæˆï¼å…±æ‰¾åˆ° 28377 ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28377/28377 [03:30<00:00, 135.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "å¤„ç†å®Œæˆï¼\n",
      "âœ… æˆåŠŸå¤åˆ¶: 28377\n",
      "âŒ æ–‡ä»¶ç¼ºå¤±: 0\n",
      "ğŸ“‚ è¾“å‡ºç›®å½•: X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\n",
      "\n",
      "ç”Ÿæˆçš„ç›®å½•ç»“æ„ç¤ºä¾‹:\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\train\\Cargo\\0_1.wav\n",
      "  X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\\test\\Background\\4_0_1.wav\n",
      "  (æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥ä½äºç±»åˆ«æ–‡ä»¶å¤¹ä¸‹ï¼Œæ— å¤šä½™å±‚çº§)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "split_dataset_unified()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb50296",
   "metadata": {},
   "source": [
    "# å› ä¸ºå™ªå£°ç±»å·²ç»åˆ‡å‰²è¿‡äº†ï¼Œæ‰€ä»¥ä¸åšåˆ‡å‰²å¤„ç†ï¼Œç­‰å…¶å®ƒç±»åšäº†åˆ‡å‰²åå†ä¸€èµ·åšé¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a47393",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = Path(r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split\")\n",
    "OUTPUT_ROOT = Path(r\"X:\\\\æ•°æ®é›†\\\\DeepShip\\\\data_preprocessing\\\\data_audio_rename_add_enviromental_noise_class_dataset_split_preprocessed\")\n",
    "\n",
    "# éŸ³é¢‘å‚æ•°\n",
    "FRAME_DURATION = 3.0   # åˆ‡ç‰‡æ—¶é•¿ 3ç§’\n",
    "OVERLAP_RATE = 0.0     # 0é‡å \n",
    "TARGET_SR = 32000      # ç›®æ ‡é‡‡æ ·ç‡\n",
    "TARGET_RMS = 0.05      # ç›®æ ‡ RMS å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mean(frame: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"å»ä¸­å¿ƒåŒ–: ç§»é™¤ç›´æµåˆ†é‡\"\"\"\n",
    "    return frame - np.mean(frame)\n",
    "\n",
    "def rms_normalize(frame: np.ndarray, target_rms: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"RMS å½’ä¸€åŒ–\"\"\"\n",
    "    rms = np.sqrt(np.mean(frame ** 2) + 1e-12)\n",
    "    if rms < 1e-8:\n",
    "        # å¦‚æœæ˜¯é™éŸ³ç‰‡æ®µï¼Œç›´æ¥è¿”å›å…¨0\n",
    "        return np.zeros_like(frame)\n",
    "    scale = target_rms / rms\n",
    "    return frame * scale\n",
    "\n",
    "def process_and_save(audio_data, save_path, sr):\n",
    "    \"\"\"ç»Ÿä¸€çš„åå¤„ç†æµæ°´çº¿ï¼šå»ä¸­å¿ƒåŒ– -> å½’ä¸€åŒ– -> ä¿å­˜\"\"\"\n",
    "    # å»ä¸­å¿ƒåŒ–\n",
    "    audio_data = remove_mean(audio_data)\n",
    "    \n",
    "    # å½’ä¸€åŒ–\n",
    "    audio_data = rms_normalize(audio_data, target_rms=TARGET_RMS)\n",
    "    \n",
    "    # ä¿å­˜ (float32)\n",
    "    wavfile.write(save_path, sr, audio_data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01c9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_smart_resample():\n",
    "    if not INPUT_ROOT.exists():\n",
    "        print(f\"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ {INPUT_ROOT}\")\n",
    "        return\n",
    "\n",
    "    # éå† train å’Œ test\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        split_in_dir = INPUT_ROOT / split\n",
    "        split_out_dir = OUTPUT_ROOT / split\n",
    "        \n",
    "        if not split_in_dir.exists():\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: {split} ...\")\n",
    "\n",
    "        # è·å–å½“å‰åˆ’åˆ†ä¸‹çš„æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹\n",
    "        categories = [d.name for d in split_in_dir.iterdir() if d.is_dir()]\n",
    "        \n",
    "        for category in categories:\n",
    "            in_cat_dir = split_in_dir / category\n",
    "            out_cat_dir = split_out_dir / category\n",
    "            out_cat_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            wav_paths = sorted(list(in_cat_dir.glob(\"*.wav\")))\n",
    "            if not wav_paths:\n",
    "                continue\n",
    "            \n",
    "            print(f\"ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: {category} ({len(wav_paths)} ä¸ªæ–‡ä»¶)\")\n",
    "\n",
    "            # åˆ¤æ–­æ˜¯å¦ä¸ºèƒŒæ™¯å™ªå£°ç±»\n",
    "            is_noise_class = (category == \"Background\")\n",
    "\n",
    "            for wav_path in tqdm(wav_paths, desc=f\"     Processing {category}\", leave=False):\n",
    "                try:\n",
    "                    # å…ˆä½¿ç”¨ sr=None åŠ è½½ï¼Œè·å–åŸå§‹é‡‡æ ·ç‡\n",
    "                    audio, sr = librosa.load(wav_path, sr=None)\n",
    "                    \n",
    "                    # åªæœ‰å½“é‡‡æ ·ç‡ä¸åŒ¹é…æ—¶ï¼Œæ‰è¿›è¡Œé‡é‡‡æ ·\n",
    "                    if sr != TARGET_SR:\n",
    "                        print(f\"é‡é‡‡æ ·: {wav_path.name} ({sr}Hz -> {TARGET_SR}Hz)\")\n",
    "                        audio = librosa.resample(audio, orig_sr=sr, target_sr=TARGET_SR)\n",
    "                        sr = TARGET_SR\n",
    "                    \n",
    "                    file_stem = wav_path.stem \n",
    "                    \n",
    "                    # åœºæ™¯ A: èƒŒæ™¯å™ªå£°ç±» (ä¸åˆ‡å‰²)\n",
    "                    if is_noise_class:\n",
    "                        target_len = int(FRAME_DURATION * sr)\n",
    "                        if len(audio) < target_len:\n",
    "                            audio = np.pad(audio, (0, target_len - len(audio)), mode='constant')\n",
    "                        elif len(audio) > target_len:\n",
    "                            audio = audio[:target_len]\n",
    "                        \n",
    "                        save_name = f\"{file_stem}.wav\"\n",
    "                        process_and_save(audio, out_cat_dir / save_name, sr)\n",
    "\n",
    "                    # åœºæ™¯ B: èˆ¹åªç±» (åˆ‡å‰²ï¼Œé‡å‘½åä¸º X_X_1.wav)\n",
    "                    else:\n",
    "                        frame_length = int(FRAME_DURATION * sr)\n",
    "                        hop_length = int(frame_length * (1.0 - OVERLAP_RATE))\n",
    "                        \n",
    "                        if len(audio) < frame_length:\n",
    "                            audio = np.pad(audio, (0, frame_length - len(audio)), mode='constant')\n",
    "                        \n",
    "                        frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=hop_length).T\n",
    "                        \n",
    "                        # start=1: ç´¢å¼•ä»1å¼€å§‹\n",
    "                        for i, frame in enumerate(frames, start=1):\n",
    "                            save_name = f\"{file_stem}_{i}.wav\"\n",
    "                            process_and_save(frame, out_cat_dir / save_name, sr)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ å¤„ç†å‡ºé”™ {wav_path.name}: {e}\")\n",
    "\n",
    "    print(\"\\nâœ… æ‰€æœ‰æ–‡ä»¶é¢„å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {OUTPUT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad66a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: train ...\n",
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Background (19635 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Cargo (78 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Passengership (120 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tanker (158 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tug (42 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ æ­£åœ¨å¤„ç†æ•°æ®é›†åˆ’åˆ†: test ...\n",
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Background (8133 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Cargo (31 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Passengership (71 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tanker (82 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†ç±»åˆ«: Tug (27 ä¸ªæ–‡ä»¶)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ‰€æœ‰æ–‡ä»¶é¢„å¤„ç†å®Œæˆï¼\n",
      "è¾“å‡ºç›®å½•: X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\data_audio_rename_add_enviromental_noise_class_dataset_split_preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œå¤„ç†\n",
    "preprocess_dataset_smart_resample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25822172",
   "metadata": {},
   "source": [
    "# æ·»åŠ é«˜æ–¯ç™½å™ªå£°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f75f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_ROOT = Path(r\"X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\data_audio_rename_add_enviromental_noise_class_dataset_split_preprocessed\")\n",
    "\n",
    "ANNOTATION_CSV = Path(r\"X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\annotation\\DeepShip_No_Overlap_add_Environmental_Noise_Segmented_Metadata.csv\")\n",
    "\n",
    "DEST_ROOT = Path(r\"X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\data_audio_rename_add_enviromental_noise_class_frame_and_window_3s_0%_16kHz_train_val_test_RMS_noisy_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf69d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RANGE = (-12, 6)\n",
    "EVAL_SNRS = np.array([-12, -9, -6, -3, 0, 3, 6], dtype=np.int32)\n",
    "\n",
    "ID_TO_FOLDER = {\n",
    "    0: 'Cargo',\n",
    "    1: 'Passengership',\n",
    "    2: 'Tanker',\n",
    "    3: 'Tug',\n",
    "    4: 'Background'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c60e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_with_snr(signal, target_snr_db, rng):\n",
    "    \"\"\"\n",
    "    æ ¹æ®ç›®æ ‡ SNR æ·»åŠ é«˜æ–¯ç™½å™ªå£°\n",
    "    \"\"\"\n",
    "    # è®¡ç®—ä¿¡å·åŠŸç‡ (é¿å…é™¤ä»¥0ï¼ŒåŠ æå°å€¼)\n",
    "    signal_power = np.mean(signal ** 2) + 1e-12\n",
    "    \n",
    "    # å°† dB è½¬ä¸ºçº¿æ€§æ¯”ä¾‹: SNR = P_signal / P_noise\n",
    "    snr_linear = 10 ** (target_snr_db / 10.0)\n",
    "    \n",
    "    # è®¡ç®—éœ€è¦çš„å™ªå£°åŠŸç‡\n",
    "    noise_power = signal_power / snr_linear\n",
    "    \n",
    "    # ç”Ÿæˆé«˜æ–¯ç™½å™ªå£° (å‡å€¼0, æ ‡å‡†å·® sqrt(power))\n",
    "    noise = rng.normal(0.0, np.sqrt(noise_power), size=signal.shape)\n",
    "    \n",
    "    return signal + noise\n",
    "\n",
    "def get_wav_path(root, split, class_id, filename):\n",
    "    \"\"\"æ„å»ºå¸¦ç±»åˆ«å­æ–‡ä»¶å¤¹çš„è·¯å¾„\"\"\"\n",
    "    folder_name = ID_TO_FOLDER.get(class_id)\n",
    "    if not folder_name:\n",
    "        raise ValueError(f\"æœªçŸ¥çš„ class_id: {class_id}\")\n",
    "    return root / split / folder_name / filename, folder_name\n",
    "\n",
    "# ================= 4. ä¸»å¤„ç†é€»è¾‘ =================\n",
    "\n",
    "def generate_noisy_dataset():\n",
    "    if not ANNOTATION_CSV.exists():\n",
    "        print(f\"âŒ é”™è¯¯: æ‰¾ä¸åˆ° CSV æ–‡ä»¶ {ANNOTATION_CSV}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(ANNOTATION_CSV)\n",
    "    print(f\"ğŸ“„ åŠ è½½æ ‡æ³¨æ–‡ä»¶ï¼Œå…± {len(df)} æ¡æ•°æ®\")\n",
    "    \n",
    "    # åˆå§‹åŒ–éšæœºç”Ÿæˆå™¨\n",
    "    train_rng = np.random.default_rng(42)\n",
    "    \n",
    "    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "    DEST_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Noise\"):\n",
    "        # 1. è§£æä¿¡æ¯ (æ ¹æ®æ‚¨ä¹‹å‰çš„CSVåˆ—å)\n",
    "        # æ³¨æ„: è¿™é‡Œå‡è®¾æ‚¨çš„CSVåˆ—åä¸º 'dataset_split', 'class_id', 'new_filename'\n",
    "        # å¦‚æœæ‚¨çš„åˆ—åä¸åŒï¼Œè¯·åœ¨æ­¤å¤„ä¿®æ”¹ï¼Œä¾‹å¦‚ row['split']\n",
    "        split = row.get(\"dataset_split\", row.get(\"split\")) \n",
    "        class_id = row.get(\"class_id\", 0) # é»˜è®¤ä¸º0æˆ–æŠ¥é”™\n",
    "        fname = row.get(\"new_filename\", row.get(\"segmented_filename\"))\n",
    "        \n",
    "        # 2. è¯»å–åŸå§‹éŸ³é¢‘\n",
    "        try:\n",
    "            wav_path, folder_name = get_wav_path(SOURCE_ROOT, split, class_id, fname)\n",
    "            if not wav_path.exists():\n",
    "                # å°è¯•å®¹é”™: æœ‰äº›æ—¶å€™ filename å¯èƒ½ä¸å¸¦åç¼€\n",
    "                if not str(wav_path).endswith('.wav'):\n",
    "                    wav_path = wav_path.with_suffix('.wav')\n",
    "                \n",
    "                if not wav_path.exists():\n",
    "                    # print(f\"âš ï¸ ç¼ºå¤±æ–‡ä»¶: {wav_path}\")\n",
    "                    continue\n",
    "\n",
    "            audio, sr = sf.read(wav_path)\n",
    "            audio = audio.astype(np.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¯»å–é”™è¯¯ {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # ==========================================\n",
    "        # é€»è¾‘ A: è®­ç»ƒé›† (éšæœº SNRï¼Œä¿æŒç›®å½•ç»“æ„)\n",
    "        # ==========================================\n",
    "        if split == \"train\":\n",
    "            # éšæœºé€‰æ‹©ä¸€ä¸ª SNR\n",
    "            snr = train_rng.integers(TRAIN_RANGE[0], TRAIN_RANGE[1] + 1)\n",
    "            \n",
    "            # ä½¿ç”¨éšæœºç§å­ç”Ÿæˆå™ªå£°\n",
    "            seed = train_rng.integers(0, 2**32 - 1)\n",
    "            noisy_audio = add_noise_with_snr(audio, snr, np.random.default_rng(seed))\n",
    "            \n",
    "            # ä¿å­˜è·¯å¾„: DEST / train / Category / file.wav\n",
    "            out_dir = DEST_ROOT / \"train\" / folder_name\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            sf.write(out_dir / fname, noisy_audio, sr, subtype=\"FLOAT\")\n",
    "\n",
    "        # ==========================================\n",
    "        # é€»è¾‘ B: æµ‹è¯•é›†/éªŒè¯é›† (å›ºå®š SNR ç»„ï¼Œåˆ†æ–‡ä»¶å¤¹å­˜æ”¾)\n",
    "        # ==========================================\n",
    "        else: # test\n",
    "            for snr in EVAL_SNRS:\n",
    "                # ç¡®å®šæ€§ç§å­ (ä¿è¯å¤ç°æ€§: åŒä¸€ä¸ªæ–‡ä»¶åœ¨åŒä¸€ä¸ªSNRä¸‹ç”Ÿæˆçš„å™ªå£°æ°¸è¿œä¸€æ ·)\n",
    "                seed_input = f\"{fname}-{snr}\"\n",
    "                seed = np.uint32(abs(hash(seed_input)) & 0xFFFFFFFF)\n",
    "                \n",
    "                noisy_audio = add_noise_with_snr(audio, snr, np.random.default_rng(seed))\n",
    "                \n",
    "                # ä¿å­˜è·¯å¾„: DEST / test / SNR_XdB / Category / file.wav\n",
    "                snr_folder_name = f\"SNR_{snr:+d}dB\"\n",
    "                out_dir = DEST_ROOT / split / snr_folder_name / folder_name\n",
    "                out_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                sf.write(out_dir / fname, noisy_audio, sr, subtype=\"FLOAT\")\n",
    "\n",
    "    print(\"\\nâœ… å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {DEST_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a690218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ åŠ è½½æ ‡æ³¨æ–‡ä»¶ï¼Œå…± 84236 æ¡æ•°æ®\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Noise: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84236/84236 [42:58<00:00, 32.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… å¤„ç†å®Œæˆï¼\n",
      "è¾“å‡ºç›®å½•: X:\\æ•°æ®é›†\\DeepShip\\data_preprocessing\\data_audio_rename_add_enviromental_noise_class_frame_and_window_3s_0%_16kHz_train_val_test_RMS_noisy_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œ\n",
    "generate_noisy_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
