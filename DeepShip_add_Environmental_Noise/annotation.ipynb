{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81520a2",
   "metadata": {},
   "source": [
    "# DeepShip 数据集加环境噪声类后的标注文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "253b2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f565bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功读取 CSV文件，共 610 条记录。\n"
     ]
    }
   ],
   "source": [
    "# 配置输入文件路径\n",
    "csv_path = r'X:\\\\数据集\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip.csv'\n",
    "train_txt_path = r'X:\\\\数据集\\\\DeepShip\\\\annotation_original\\\\training_and_testing\\\\train.txt'\n",
    "test_txt_path = r'X:\\\\数据集\\\\DeepShip\\\\annotation_original\\\\training_and_testing\\\\test.txt'\n",
    "output_csv_path = r'X:\\\\数据集\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata.csv'\n",
    "\n",
    "# 读取原始 CSV\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"成功读取 CSV文件，共 {len(df)} 条记录。\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"未找到文件: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96758a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新文件名示例:\n",
      "   ID  class_id new_filename\n",
      "0   1         0      0_1.wav\n",
      "1   2         0      0_2.wav\n",
      "2   3         0      0_3.wav\n",
      "3   4         0      0_4.wav\n",
      "4   5         0      0_5.wav\n"
     ]
    }
   ],
   "source": [
    "df['new_filename'] = df.apply(lambda row: f\"{row['class_id']}_{row['ID']}.wav\", axis=1)\n",
    "\n",
    "print(\"新文件名示例:\")\n",
    "print(df[['ID', 'class_id', 'new_filename']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42133b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_keys(file_path):\n",
    "    keys = set()\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"警告: 文件不存在 {file_path}\")\n",
    "        return keys\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            parts = line.split('/')\n",
    "            if len(parts) >= 3:\n",
    "                class_name = parts[-3]\n",
    "                folder_name = parts[-2]\n",
    "                keys.add((class_name, folder_name))\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "407996e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 X:\\\\数据集\\\\DeepShip\\\\annotation_original\\\\training_and_testing\\\\train.txt 解析出 398 个唯一文件夹 (Train)\n",
      "从 X:\\\\数据集\\\\DeepShip\\\\annotation_original\\\\training_and_testing\\\\test.txt 解析出 211 个唯一文件夹 (Test)\n"
     ]
    }
   ],
   "source": [
    "# 加载训练集和测试集的标识键\n",
    "train_keys = get_split_keys(train_txt_path)\n",
    "test_keys = get_split_keys(test_txt_path)\n",
    "\n",
    "print(f\"从 {train_txt_path} 解析出 {len(train_keys)} 个唯一文件夹 (Train)\")\n",
    "print(f\"从 {test_txt_path} 解析出 {len(test_keys)} 个唯一文件夹 (Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbd5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据集划分统计:\n",
      "dataset_split\n",
      "train         398\n",
      "test          211\n",
      "unassigned      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "注意：以下数据未被分配 (可能缺失元数据):\n",
      "    ID Ship Name folder_name\n",
      "21  23   GALLEON         NaN\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {\n",
    "    0: 'Cargo',\n",
    "    1: 'Passengership',\n",
    "    2: 'Tanker',\n",
    "    3: 'Tug'\n",
    "}\n",
    "\n",
    "def assign_split_label(row):\n",
    "    if pd.isna(row['folder_name']): return 'unassigned'\n",
    "    txt_class = class_mapping.get(row['class_id'])\n",
    "    key = (txt_class, row['folder_name'])\n",
    "    \n",
    "    if key in train_keys: return 'train'\n",
    "    elif key in test_keys: return 'test'\n",
    "    else: return 'unassigned'\n",
    "\n",
    "df['dataset_split'] = df.apply(assign_split_label, axis=1)\n",
    "\n",
    "# 打印统计结果\n",
    "split_counts = df['dataset_split'].value_counts()\n",
    "print(\"\\n数据集划分统计:\")\n",
    "print(split_counts)\n",
    "\n",
    "# 检查是否有未分配的数据 (通常是ID 23, 因为缺失folder_name)\n",
    "unassigned = df[df['dataset_split'] == 'unassigned']\n",
    "if len(unassigned) > 0:\n",
    "    print(\"\\n注意：以下数据未被分配 (可能缺失元数据):\")\n",
    "    print(unassigned[['ID', 'Ship Name', 'folder_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9e00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已剔除未分配数据 1 条。\n",
      "\n",
      "最终划分统计结果:\n",
      "dataset_split\n",
      "train    398\n",
      "test     211\n",
      "Name: count, dtype: int64\n",
      "\n",
      "处理完成！文件已保存为: X:\\\\数据集\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata.csv\n"
     ]
    }
   ],
   "source": [
    "df_clean = df[df['dataset_split'] != 'unassigned'].copy()\n",
    "print(f\"已剔除未分配数据 {len(df) - len(df_clean)} 条。\")\n",
    "\n",
    "target_columns = [\n",
    "    'ID', \n",
    "    'new_filename',\n",
    "    'class_id', \n",
    "    'class ID', \n",
    "    'Ship Name', \n",
    "    'folder_name', \n",
    "    'Date & Time',\n",
    "    'Duration(sec)',\n",
    "    'Distances(m)',\n",
    "    'prompt_en',\n",
    "    'dataset_split'\n",
    "]\n",
    "\n",
    "# 确保列都存在\n",
    "df_final = df_clean[target_columns]\n",
    "\n",
    "# 打印统计信息\n",
    "print(\"\\n最终划分统计结果:\")\n",
    "print(df_final['dataset_split'].value_counts())\n",
    "\n",
    "# 保存文件\n",
    "df_final.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\n处理完成！文件已保存为: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b912a7",
   "metadata": {},
   "source": [
    "# 处理海洋环境噪声的标注信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d63dbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_csv_path = r\"X:\\\\数据集\\\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata.csv\"\n",
    "output_csv_path = r\"X:\\数据集\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata_add_Environmental_Noise.csv\"\n",
    "\n",
    "# 噪声数据的根目录\n",
    "NOISE_ROOT_PATH = r'X:\\数据集\\DeepShip\\data_original\\background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4033e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 4 类数据加载完成: 609 条记录\n"
     ]
    }
   ],
   "source": [
    "df_ship = pd.read_csv(original_csv_path)\n",
    "print(f\"原始 4 类数据加载完成: {len(df_ship)} 条记录\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468dce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始执行文件重命名 ===\n",
      "正在扫描目录: X:\\数据集\\DeepShip\\data_original\\background\\train\n",
      "正在扫描目录: X:\\数据集\\DeepShip\\data_original\\background\\test\n",
      "已重命名 27700 个文件...\n",
      "重命名完成! 共修改 27768 个文件, 失败 0 个。\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 开始执行文件重命名 ===\")\n",
    "def rename_noise_files(root_path):\n",
    "    count = 0\n",
    "    errors = 0\n",
    "    \n",
    "    # 遍历 train 和 test\n",
    "    for split in ['train', 'test']:\n",
    "        split_dir = os.path.join(root_path, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            print(f\"警告: 找不到目录 {split_dir}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"正在扫描目录: {split_dir}\")\n",
    "        \n",
    "        # 使用 os.walk 遍历\n",
    "        for root, dirs, files in os.walk(split_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav'):\n",
    "                    # 检查文件名是否已经是目标格式 (防止重复运行导致错误)\n",
    "                    if file.startswith('4_') and file.count('_') >= 2:\n",
    "                        continue\n",
    "                        \n",
    "                    old_path = os.path.join(root, file)\n",
    "                    \n",
    "                    try:\n",
    "                        # === 解析路径逻辑 ===\n",
    "                        # 示例路径: ...\\3_0\\0000\\00000.wav\n",
    "                        path_parts = os.path.normpath(old_path).split(os.sep)\n",
    "                        \n",
    "                        # 1. 提取 FileID (00000 -> 1)\n",
    "                        file_stem = os.path.splitext(file)[0]\n",
    "                        try:\n",
    "                            file_num_id = int(file_stem) + 1 # 00000 -> 1\n",
    "                        except ValueError:\n",
    "                            # 如果文件名不是纯数字，可能需要特殊处理，或者跳过\n",
    "                            print(f\"跳过非数字文件名: {file}\")\n",
    "                            continue\n",
    "\n",
    "                        # 2. 提取 FolderID (3_0 -> 0)\n",
    "                        # 寻找包含 '_' 的上级目录\n",
    "                        parent = path_parts[-2]      # 0000\n",
    "                        grandparent = path_parts[-3] # 3_0\n",
    "                        \n",
    "                        target_folder = grandparent if '_' in grandparent else parent\n",
    "                        \n",
    "                        if '_' in target_folder:\n",
    "                            folder_id_part = target_folder.split('_')[-1]\n",
    "                        else:\n",
    "                            # 如果找不到下划线，尝试用当前目录名\n",
    "                            folder_id_part = target_folder\n",
    "                            \n",
    "                        # === 构造新文件名 ===\n",
    "                        # 格式: 4_{FolderID}_{FileID}.wav\n",
    "                        new_filename = f\"4_{folder_id_part}_{file_num_id}.wav\"\n",
    "                        new_path = os.path.join(root, new_filename)\n",
    "                        \n",
    "                        # === 执行重命名 ===\n",
    "                        if old_path != new_path:\n",
    "                            os.rename(old_path, new_path)\n",
    "                            count += 1\n",
    "                            if count % 100 == 0:\n",
    "                                print(f\"已重命名 {count} 个文件...\", end='\\r')\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        print(f\"重命名失败: {old_path}, 错误: {e}\")\n",
    "                        errors += 1\n",
    "\n",
    "    print(f\"\\n重命名完成! 共修改 {count} 个文件, 失败 {errors} 个。\")\n",
    "    \n",
    "# 执行重命名函数\n",
    "rename_noise_files(NOISE_ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cea207f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 开始生成标注信息 ===\n",
      "成功读取原始数据。\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 开始生成标注信息 ===\")\n",
    "\n",
    "if os.path.exists(original_csv_path):\n",
    "    df_ship = pd.read_csv(original_csv_path)\n",
    "    print(\"成功读取原始数据。\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"未找到原始文件: {original_csv_path}\")\n",
    "\n",
    "# 扫描已重命名的文件\n",
    "def scan_renamed_files(root_path):\n",
    "    noise_rows = []\n",
    "    # === 修改处：ID 从 1 开始独立计数 ===\n",
    "    current_id = 1 \n",
    "    \n",
    "    for split in ['train', 'test']:\n",
    "        split_dir = os.path.join(root_path, split)\n",
    "        if not os.path.exists(split_dir): continue\n",
    "        \n",
    "        for root, dirs, files in os.walk(split_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav') and file.startswith('4_'):\n",
    "                    \n",
    "                    # 获取 folder_name\n",
    "                    path_parts = os.path.normpath(root).split(os.sep)\n",
    "                    parent = path_parts[-1] \n",
    "                    grandparent = path_parts[-2] \n",
    "                    raw_folder_name = grandparent if '_' in grandparent else parent\n",
    "\n",
    "                    row = {\n",
    "                        'ID': current_id,\n",
    "                        'new_filename': file,  \n",
    "                        'class_id': 4,\n",
    "                        'class ID': None,\n",
    "                        'Ship Name': 'Marine Environmental Noise',\n",
    "                        'folder_name': raw_folder_name, \n",
    "                        'Date & Time': 'Unknown',\n",
    "                        'Duration(sec)': 3,\n",
    "                        'Distances(m)': None,\n",
    "                        'prompt_en': 'Hydrophone recording of marine environmental noise.',\n",
    "                        'dataset_split': split\n",
    "                    }\n",
    "                    noise_rows.append(row)\n",
    "                    # 计数器递增\n",
    "                    current_id += 1\n",
    "                    \n",
    "    return pd.DataFrame(noise_rows)\n",
    "\n",
    "# 执行扫描\n",
    "df_noise = scan_renamed_files(NOISE_ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e2931cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扫描到 27768 条噪声数据。\n",
      "噪声数据的 ID 范围: 1 - 27768\n",
      "\n",
      "最终处理完成！文件已保存至: X:\\数据集\\DeepShip\\\\data_preprocessing\\\\annotation\\\\DeepShip_No_Overlap_Metadata_add_Environmental_Noise.csv\n"
     ]
    }
   ],
   "source": [
    "if len(df_noise) > 0:\n",
    "    print(f\"扫描到 {len(df_noise)} 条噪声数据。\")\n",
    "    print(f\"噪声数据的 ID 范围: {df_noise['ID'].min()} - {df_noise['ID'].max()}\")\n",
    "    \n",
    "    # 2.3 合并数据\n",
    "    target_columns = [\n",
    "        'ID', 'new_filename', 'class_id', 'class ID', \n",
    "        'Ship Name', 'folder_name', 'Date & Time', \n",
    "        'Duration(sec)', 'Distances(m)', 'prompt_en', 'dataset_split'\n",
    "    ]\n",
    "    \n",
    "    # 确保列一致\n",
    "    df_ship_aligned = df_ship[target_columns]\n",
    "    df_noise_aligned = df_noise[target_columns]\n",
    "    \n",
    "    # 合并\n",
    "    df_final = pd.concat([df_ship_aligned, df_noise_aligned], ignore_index=True)\n",
    "    \n",
    "    # 保存\n",
    "    df_final.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\n最终处理完成！文件已保存至: {output_csv_path}\")\n",
    "else:\n",
    "    print(\"未找到任何噪声文件。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
